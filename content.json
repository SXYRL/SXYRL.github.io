{"meta":{"title":"闫瑞龙的个人博客","subtitle":null,"description":null,"author":"闫瑞龙","url":"http://yoursite.com"},"pages":[{"title":"","date":"2018-02-28T13:41:16.976Z","updated":"2018-02-28T13:41:16.976Z","comments":false,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"categories","date":"2018-02-28T13:40:53.000Z","updated":"2018-02-28T13:40:53.025Z","comments":true,"path":"categories/index1.html","permalink":"http://yoursite.com/categories/index1.html","excerpt":"","text":""},{"title":"tags","date":"2018-02-28T13:39:07.000Z","updated":"2018-02-28T13:40:27.611Z","comments":true,"path":"tags/index1.html","permalink":"http://yoursite.com/tags/index1.html","excerpt":"","text":""},{"title":"","date":"2018-02-28T13:40:14.186Z","updated":"2018-02-28T13:40:14.186Z","comments":false,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"LEGB规则","slug":"LEGB规则","date":"2017-04-12T16:00:00.000Z","updated":"2018-03-08T15:20:18.579Z","comments":true,"path":"2017/04/13/LEGB规则/","link":"","permalink":"http://yoursite.com/2017/04/13/LEGB规则/","excerpt":"","text":"—————————————————————————————————————————————————转自：https://foofish.net/python-legb.html 作者：FOOFISH-PYTHON之禅—————————————————————————————————————————————————理解LEGB前，首先需要对Python的作用域、命名空间有一定的了解，话题才能继续展开。 命名空间 命名空间表示变量的可见范围，一个变量名可以定义在多个不同的命名空间，相互之间并不冲突，但同一个命名空间中不能有两个相同的变量名。比如：两个叫“张三”的学生可以同时存在于班级A和班级B中，如果两个张三都是一个班级，那么带来的麻烦复杂很多了，在Python中你不能这么干。 在Python中用字典来表示一个命名空间，命名空间中保存了变量（名字）和对象的映射关系，在Python中命名空间出现在哪些地方呢？有函数范围内的命名空间（local），有模块范围内的命名空间（global），有python内建的命名空间（built-in），还有类对象的所有属性组成的命名空间。 命名空间的生命周期 所有的命名空间都是有生命周期的，对于python内建的命名空间，python解析器启动时创建，一直保留直至直python解析器退出时才消亡。而对于函数的local命名空间是在函数每次被调用的时候创建，调用完成函数返回时消亡，而对于模块的global命名空间是在该模块被import的时候创建，解析器退出时消亡。 作用域 一个作用域是指一段程序的正文区域，可以是一个函数或一段代码。一个变量的作用域是指该变量的有效范围。Python的作用域是静态作用域，因为它是由代码中得位置决定的，而命名空间就是作用域的动态表现。 LGB Python2.2之前定义了三个作用域，分别是： global作用域，对应的global命名空间，一个模块最外层定义的一个作用域。 local作用域，对应local命名空间，由函数定义的。 builtin作用域，对应builtin命名空间，python内部定义的最顶层的作用域，在这个作用域里面定义了各种内建函数：open、range、xrange、list等等。 那时的Python作用域规则叫做LEB规则，变量（名字）的引用按照local作用域、global作用域、builtin作用域的顺序来查找。 首先来看一段代码: a = 1 def foo(): a = 2 print a //[1] print a //[2] foo() [1]处输出结果为2，Python首先会在函数foo定义的local作用域中查找名字a，如果找到了直接输出，没有没找到就会在模块定义的global作用域中查找，如果还没找到，就到Python内建的builtin作用域中查找a，如果还没找到就报异常：NameError: name ‘a’ is not defined。引用过程如图： [2]处输出结果为1，查找顺序同样是按照LGB规则，只不过这里的local作用域就是global作用域。 LEGB规则Python2.2开始引入嵌套函数，嵌套函数为python提供了闭包实现。 a = 1 def foo(): a = 2 def bar(): print a //[1] return bar func = foo() func() 函数bar和a=2捆包在一起组成一个闭包，因此这里a=2即使脱离了foo所在的local作用域，但调用func的时候（其实就是调用bar）查找名字a的顺序是LEGB规则，这里的E就是enclosing的缩写，代表的“直接外围作用域”这个概念。查找a时，在bar对应的local作用域中没有时，然后在它外围的作用域中查找a。LEGB规定了查找一个名称的顺序为：local–&gt;enclosing–&gt;global–&gt;builtin。","categories":[{"name":"python","slug":"python","permalink":"http://yoursite.com/categories/python/"}],"tags":[{"name":"命名空间 作用域 LEGB","slug":"命名空间-作用域-LEGB","permalink":"http://yoursite.com/tags/命名空间-作用域-LEGB/"}]},{"title":"python 中locals() 和 globals()","slug":"locals() 和 globals()","date":"2017-04-11T16:00:00.000Z","updated":"2018-03-08T15:10:36.192Z","comments":true,"path":"2017/04/12/locals() 和 globals()/","link":"","permalink":"http://yoursite.com/2017/04/12/locals() 和 globals()/","excerpt":"","text":"1、locals() 和 globals() 是python 的内建函数，他们提供了字典的形式访问局部变量和全局变量的方式。 def test(arg): a=1 b=2 data_dict = {} print locals() print globals() if __name__ == &apos;__main__&apos;: test(3) 输出为： {&apos;data_dict&apos;: {}, &apos;b&apos;: 2, &apos;a&apos;: 1, &apos;arg&apos;: 3} {&apos;__name__&apos;: &apos;__main__&apos;, &apos;__doc__&apos;: None, &apos;__package__&apos;: None, &apos;__loader__&apos;: &lt;class &apos;_frozen_importlib.BuiltinImporter&apos;&gt;, &apos;__spec__&apos;: None, &apos;__annotations__&apos;: {}, &apos;__builtins__&apos;: &lt;module &apos;builtins&apos; (built-in)&gt;, &apos;__file__&apos;: &apos;C:/Users/闫瑞龙/Desktop/demo/locals.py&apos;, &apos;test&apos;: &lt;function test at 0x000001E26680C598&gt;} 2、locals() 返回是当前局部变量的深拷贝，修改locals() 中变量值的时候，实际上对于原变量本身是没有任何影响的。而globals()返回的是全局变量的字典，修改其中的内容，值会真正的发生改变。示例代码： b = 5 # 定义一个全局变量 def test2(): a=1 locals()[&quot;a&quot;] = 2 # 修改局部变量 print &quot;a=&quot;, a globals()[&quot;b&quot;] = 6 # 修改全局变量 print &quot;b=&quot;, b if __name__ == &apos;__main__&apos;: test2() 输出为： a= 1 b= 6","categories":[{"name":"python","slug":"python","permalink":"http://yoursite.com/categories/python/"}],"tags":[{"name":"内置函数","slug":"内置函数","permalink":"http://yoursite.com/tags/内置函数/"}]},{"title":"作用域","slug":"作用域","date":"2017-04-10T16:00:00.000Z","updated":"2018-03-08T15:11:44.596Z","comments":true,"path":"2017/04/11/作用域/","link":"","permalink":"http://yoursite.com/2017/04/11/作用域/","excerpt":"","text":"LEGB原则 python中作用域有四种： L （Local） 局部作用域 E （Enclosing） 闭包函数外的函数中 G （Global） 全局作用域 B （Built-in） 内建作用域 python按照LEGB原则搜索变量，即优先级L&gt;E&gt;G&gt;B。 dir = 1 # Global def outer(): dir = 2 # Enclosing def inner(): dir = 3 # Local return dir return inner print outer() # 输出3 作用域（Scope）和命名空间（NameSpace） def/lambda会创建新的作用域，生成器表达式都有引入新的作用域，class的定义没有作用域，只是创建一个隔离的命名空间。在Python中，scope是由namespace按特定的层级结构组合起来的。scope一定是namespace，但namespace不一定是scope。命名空间跟作用域的区别是，它不能在里面再嵌套其他作用域。下面看两个例子。 例1： a = 1 def test(): a += 1 a = 2 test() #异常 UnboundLocalError: local variable ‘a’ referenced before assignment。这是因为解释器看到a+=1时，按照LEGB优先在Local中找到了a的声明，执行时先a+=1在a=2声明之前，所以抛出异常。 例2： class A(object): x = 2 gen = (x*i for i in xrange(5)) if __name__ == &quot;__main__&quot;: a = A() print list(a.gen)#异常 上面的代码会抛出异常：NameError: global name ‘x’ is not defined。这是因为gen = （x for _ in xrange(5）是生成器，会产生新的作用域。而classA 中并不产生作用域。按照LEGB原则，不能找到x的定义，所以抛出异常。解决这个问题有几种方案。 1，将x定义为全局变量，这样可以解决异常，但是可能违背了类的逻辑。 2，将生成器表达式改为列表表达式。 gen = [x*i for i in xrange(5)] 在python2中，列表表达式不产生新的作用域，所以不会抛出异常。但是在python3中仍有异常。 3，用A.x的方式访问类属性。 gen = (A.x*i for i in xrange(5)) 4，引入lambda函数，将class命名空间的x作为变量传入到匿名函数中。 gen = (lambda x: (x*i for i in xrange(5)))(x) 这个问题可以理解为class不能产生作用域导致的，在函数中就没有这个问题。 def test(): x = 2 gen = (i * x for i in xrange(5)) return gen gen = test() print list(gen)#输出[0, 2, 4, 6, 8]","categories":[{"name":"python","slug":"python","permalink":"http://yoursite.com/categories/python/"}],"tags":[{"name":"作用域 内建函数","slug":"作用域-内建函数","permalink":"http://yoursite.com/tags/作用域-内建函数/"}]},{"title":"如何避免循环导入","slug":"避免循环导入","date":"2017-04-09T16:00:00.000Z","updated":"2018-03-08T15:08:16.099Z","comments":true,"path":"2017/04/10/避免循环导入/","link":"","permalink":"http://yoursite.com/2017/04/10/避免循环导入/","excerpt":"","text":"1，什么是循环导入 a.py from b import b print &apos;---------this is module a.py----------&apos; def a(): print(&quot;hello, a&quot;) b() a() b.py from a import a print &apos;----------this is module b.py----------&apos; def b(): print(&quot;hello, b&quot;) def c(): a() c() 运行pyhon a.py Traceback (most recent call last): File &quot;a.py&quot;, line 1, in &lt;module&gt; from b import b File &quot;/home/yan/py_demo/01-python高级-1/b.py&quot;, line 1, in &lt;module&gt; from a import a File &quot;/home/yan/py_demo/01-python高级-1/a.py&quot;, line 1, in &lt;module&gt; from b import b ImportError: cannot import name b 怎样避免循环导入 1,例如放在函数体内导入 a.py print(&apos;---------this is module a.py----------&apos;) def a(): print(&quot;hello, a&quot;) from b import b b() a() b.py print(&apos;----------this is module b.py----------&apos;) def b(): print(&quot;hello, b&quot;) def c(): from a import a a() c() 2，程序设计上分层，降低耦合","categories":[{"name":"python","slug":"python","permalink":"http://yoursite.com/categories/python/"}],"tags":[{"name":"模块","slug":"模块","permalink":"http://yoursite.com/tags/模块/"}]},{"title":"模块导入","slug":"模块导入","date":"2017-04-06T16:00:00.000Z","updated":"2018-03-08T15:05:25.952Z","comments":true,"path":"2017/04/07/模块导入/","link":"","permalink":"http://yoursite.com/2017/04/07/模块导入/","excerpt":"","text":"在python中，每一个以 .py结尾的Python文件都是一个模块。其他的文件可以通过导入一个模块来读取该模块的内容。导入从本质上来讲，就是载入另一个文件，并能够读取那个文件的内容。一个模块的内容通过这样的属性能够被外部世界使用。 这种基于模块的方式使模块变成了Python程序架构的一个核心概念。更大的程序往往以多个模块文件的形式出现，并且导入了其他模块文件的工具。其中的一个模块文件被设计成主文件，或叫做顶层文件（就是那个启动后能够运行整个程序的文件）。 默认情况下，模块在第一次被导入之后，其他的导入都不再有效。如果此时在另一个窗口中改变并保存了模块的源代码文件，也无法更新该模块。这样设计的原因在于，导入是一个开销很大的操作（导入必须找到文件，将其编译成字节码，并且运行代码），以至于每个文件、每个程序运行不能够重复多于一次。 import 搜索路径 从下面列出的目录里依次查找要导入的模块文件 ‘’表示当前路径 In [1]: import sys In [2]: sys.path Out[2]: [&apos;&apos;, &apos;/usr/bin&apos;, &apos;/usr/lib/python35.zip&apos;, &apos;/usr/lib/python3.5&apos;, &apos;/usr/lib/python3.5/plat-x86_64-linux-gnu&apos;, &apos;/usr/lib/python3.5/lib-dynload&apos;, &apos;/usr/local/lib/python3.5/dist-packages&apos;, &apos;/usr/lib/python3/dist-packages&apos;, &apos;/usr/lib/python3/dist-packages/IPython/extensions&apos;, &apos;/home/yan/.ipython&apos;] 动态添加模块搜索路径 In [3]: sys.path.append(&apos;/home&apos;) In [4]: sys.path Out[4]: [&apos;&apos;, &apos;/usr/bin&apos;, &apos;/usr/lib/python35.zip&apos;, &apos;/usr/lib/python3.5&apos;, &apos;/usr/lib/python3.5/plat-x86_64-linux-gnu&apos;, &apos;/usr/lib/python3.5/lib-dynload&apos;, &apos;/usr/local/lib/python3.5/dist-packages&apos;, &apos;/usr/lib/python3/dist-packages&apos;, &apos;/usr/lib/python3/dist-packages/IPython/extensions&apos;, &apos;/home/yan/.ipython&apos;, &apos;/home&apos;] 设置模块路径搜索优先级 In [5]: sys.path.insert(0, &apos;/home/itcast/xxx&apos;) #可以确保先搜索这个路径 注： 程序向sys.path添加的目录只会在此程序的生命周期之内有效，其他所有的对sys.path的动态操作也是如此。 重新导入模块 模块被导入后，import module不能重新导入模块，重新导入需用 测试模块内容 test.py def test(): print(&apos;test&apos;) In [1]: import test In [2]: test.test() test 修改测试模块 def test(): print(&apos;test&apos;) print(&apos;test-1&apos;) 重新加载模块 In [3]: from imp import * In [4]: reload(test) Out[4]: &lt;module &apos;test&apos; from &apos;/home/yan/py_demo/01-python高级-1/test.py&apos;&gt; In [5]: test.test() test test-1 注意：reload函数希望获得的参数是一个已经加载了的模块对象的名称，所以如果在重载之前,请确保已经成功地导入了这个模块。","categories":[{"name":"python","slug":"python","permalink":"http://yoursite.com/categories/python/"}],"tags":[{"name":"模块","slug":"模块","permalink":"http://yoursite.com/tags/模块/"}]},{"title":"服务器动态资源请求","slug":"服务器动态资源请求","date":"2017-04-05T16:00:00.000Z","updated":"2018-03-08T14:55:08.961Z","comments":true,"path":"2017/04/06/服务器动态资源请求/","link":"","permalink":"http://yoursite.com/2017/04/06/服务器动态资源请求/","excerpt":"","text":"原文出处： 银河系1234目录： 引言一、线程1.1 普通的多线程 1.2 自定义线程类 1.3 线程锁 1.3.1 未使用锁 1.3.2 普通锁Lock和RLock 1.3.3 信号量(Semaphore) 1.3.4 事件(Event) 1.3.5 条件(condition) 1.3 全局解释器锁（GIL） 1.4 定时器（Timer） 1.5 队列 1.5.1 Queue：先进先出队列 1.5.2 LifoQueue：后进先出队列 1.5.3 PriorityQueue：优先级队列 1.5.4 deque：双向队列 1.6 生产者消费者模型 1.7 线程池 二、进程2.1 进程的数据共享 2.1.1 使用Array共享数据 2.1.2 使用Manager共享数据 2.1.3 使用queues的Queue类共享数据 2.2 进程锁 2.3 进程池 三、协程3.1 greenlet3.2 gevent 引言解释器环境：python3.5.1我们都知道python网络编程的两大必学模块socket和socketserver，其中的socketserver是一个支持IO多路复用和多线程、多进程的模块。一般我们在socketserver服务端代码中都会写这么一句： server = socketserver.ThreadingTCPServer(settings.IP_PORT, MyServer) ThreadingTCPServer这个类是一个支持多线程和TCP协议的socketserver，它的继承关系是这样的： class ThreadingTCPServer(ThreadingMixIn, TCPServer): pass 右边的TCPServer实际上是它主要的功能父类，而左边的ThreadingMixIn则是实现了多线程的类，它自己本身则没有任何代码。 MixIn在python的类命名中，很常见，一般被称为“混入”，戏称“乱入”，通常为了某种重要功能被子类继承。 class ThreadingMixIn: daemon_threads = False def process_request_thread(self, request, client_address): try: self.finish_request(request, client_address) self.shutdown_request(request) except: self.handle_error(request, client_address) self.shutdown_request(request) def process_request(self, request, client_address): t = threading.Thread(target = self.process_request_thread, args = (request, client_address)) t.daemon = self.daemon_threads t.start() 在ThreadingMixIn类中，其实就定义了一个属性，两个方法。在process_request方法中实际调用的正是python内置的多线程模块threading。这个模块是python中所有多线程的基础，socketserver本质上也是利用了这个模块。 一、线程线程，有时被称为轻量级进程(Lightweight Process，LWP），是程序执行流的最小单元。一个标准的线程由线程ID，当前指令指针(PC），寄存器集合和堆栈组成。另外，线程是进程中的一个实体，是被系统独立调度和分派的基本单位，线程自己不独立拥有系统资源，但它可与同属一个进程的其它线程共享该进程所拥有的全部资源。一个线程可以创建和撤消另一个线程，同一进程中的多个线程之间可以并发执行。由于线程之间的相互制约，致使线程在运行中呈现出间断性。线程也有就绪、阻塞和运行三种基本状态。就绪状态是指线程具备运行的所有条件，逻辑上可以运行，在等待处理机；运行状态是指线程占有处理机正在运行；阻塞状态是指线程在等待一个事件（如某个信号量），逻辑上不可执行。每一个应用程序都至少有一个进程和一个线程。线程是程序中一个单一的顺序控制流程。在单个程序中同时运行多个线程完成不同的被划分成一块一块的工作，称为多线程。以上那一段，可以不用看！举个例子，厂家要生产某个产品，在它的生产基地建设了很多厂房，每个厂房内又有多条流水生产线。所有厂房配合将整个产品生产出来，某个厂房内的所有流水线将这个厂房负责的产品部分生产出来。每个厂房拥有自己的材料库，厂房内的生产线共享这些材料。而每一个厂家要实现生产必须拥有至少一个厂房一条生产线。那么这个厂家就是某个应用程序；每个厂房就是一个进程；每条生产线都是一个线程。 1.1 普通的多线程在python中，threading模块提供线程的功能。通过它，我们可以轻易的在进程中创建多个线程。下面是个例子： import threading import time def show(arg): time.sleep(1) print(&apos;thread&apos;+str(arg)) for i in range(10): t = threading.Thread(target=show, args=(i,)) t.start() print(&apos;main thread stop&apos;) 上述代码创建了10个“前台”线程，然后控制器就交给了CPU，CPU根据指定算法进行调度，分片执行指令。下面是Thread类的主要方法： start 线程准备就绪，等待CPU调度 setName 为线程设置名称 getName 获取线程名称 setDaemon 设置为后台线程或前台线程（默认是False，前台线程） 如果是后台线程，主线程执行过程中，后台线程也在进行，主线程执行完毕后，后台线程不论成功与否，均停止。如果是前台线程，主线程执行过程中，前台线程也在进行，主线程执行完毕后，等待前台线程也执行完成后，程序停止。 join 该方法非常重要。它的存在是告诉主线程，必须在这个位置等待子线程执行完毕后，才继续进行主线程的后面的代码。但是当setDaemon为True时，join方法是无效的。 run 线程被cpu调度后自动执行线程对象的run方法 1.2 自定义线程类 对于threading模块中的Thread类，本质上是执行了它的run方法。因此可以自定义线程类，让它继承Thread类，然后重写run方法。 import threading class MyThreading(threading.Thread): def __init__(self,func,arg): super(MyThreading,self).__init__() self.func = func self.arg = arg def run(self): self.func(self.arg) def f1(args): print(args) obj = MyThreading(f1, 123) obj.start() 1.3 线程锁 CPU执行任务时，在线程之间是进行随机调度的，并且每个线程可能只执行n条代码后就转而执行另外一条线程。由于在一个进程中的多个线程之间是共享资源和数据的，这就容易造成资源抢夺或脏数据，于是就有了锁的概念，限制某一时刻只有一个线程能访问某个指定的数据。 1.3.1 未使用锁 #!/usr/bin/env python # -*- coding:utf-8 -*- import threading import time NUM = 0 def show(): global NUM NUM += 1 name = t.getName() time.sleep(1) # 注意，这行语句的位置很重要，必须在NUM被修改后，否则观察不到脏数据的现象。 print(name, &quot;执行完毕后，NUM的值为： &quot;, NUM) for i in range(10): t = threading.Thread(target=show) t.start() print(&apos;main thread stop&apos;) 上述代码运行后，结果如下： main thread stop Thread-1 执行完毕后，NUM的值为： 10 Thread-2 执行完毕后，NUM的值为： 10 Thread-4 执行完毕后，NUM的值为： 10 Thread-9 执行完毕后，NUM的值为： 10 Thread-3 执行完毕后，NUM的值为： 10 Thread-6 执行完毕后，NUM的值为： 10 Thread-8 执行完毕后，NUM的值为： 10 Thread-7 执行完毕后，NUM的值为： 10 Thread-5 执行完毕后，NUM的值为： 10 Thread-10 执行完毕后，NUM的值为： 10 由此可见，由于线程同时访问一个数据，产生了错误的结果。为了解决这个问题，python在threading模块中定义了几种线程锁类，分别是： Lock 普通锁（不可嵌套） RLock 普通锁（可嵌套）常用 Semaphore 信号量 event 事件 condition 条件 1.3.2 普通锁Lock和RLock 类名：Lock或RLock 普通锁，也叫互斥锁，是独占的，同一时刻只有一个线程被放行。 import time import threading NUM = 10 def func(lock): global NUM lock.acquire() # 让锁开始起作用 NUM -= 1 time.sleep(1) print(NUM) lock.release() # 释放锁 lock = threading.Lock() # 实例化一个锁对象 for i in range(10): t = threading.Thread(target=func, args=(lock,)) # 记得把锁当作参数传递给func参数 t.start() 以上是threading模块的Lock类，它不支持嵌套锁。RLcok类的用法和Lock一模一样，但它支持嵌套，因此我们一般直接使用RLcok类。 1.3.3 信号量(Semaphore) 类名：BoundedSemaphore 这种锁允许一定数量的线程同时更改数据，它不是互斥锁。比如地铁安检，排队人很多，工作人员只允许一定数量的人进入安检区，其它的人继续排队。 #!/usr/bin/env python # -*- coding:utf-8 -*- import time import threading def run(n): semaphore.acquire() print(&quot;run the thread: %s&quot; % n) time.sleep(1) semaphore.release() num = 0 semaphore = threading.BoundedSemaphore(5) # 最多允许5个线程同时运行 for i in range(20): t = threading.Thread(target=run, args=(i,)) t.start() 1.3.4 事件(Event) 类名：Event 事件主要提供了三个方法 set、wait、clear。 事件机制：全局定义了一个“Flag”，如果“Flag”的值为False，那么当程序执行wait方法时就会阻塞，如果“Flag”值为True，那么wait方法时便不再阻塞。这种锁，类似交通红绿灯（默认是红灯），它属于在红灯的时候一次性阻挡所有线程，在绿灯的时候，一次性放行所有的排队中的线程。 clear：将“Flag”设置为False set：将“Flag”设置为True import threading def func(e,i): print(i) e.wait() # 检测当前event是什么状态，如果是红灯，则阻塞，如果是绿灯则继续往下执行。默认是红灯。 print(i+100) event = threading.Event() for i in range(10): t = threading.Thread(target=func, args=(event, i)) t.start() event.clear() # 主动将状态设置为红灯 inp = input(&quot;&gt;&gt;&gt;&quot;) if inp == &quot;1&quot;: event.set() # 主动将状态设置为绿灯 1.3.5 条件(condition) 类名：Condition 该机制会使得线程等待，只有满足某条件时，才释放n个线程。 import threading def condition(): ret = False r = input(&quot;&gt;&gt;&gt;&quot;) if r == &quot;yes&quot;: ret = True return ret def func(conn, i): print(i) conn.acquire() conn.wait_for(condition) # 这个方法接受一个函数的返回值 print(i+100) conn.release() c = threading.Condition() for i in range(10): t = threading.Thread(target=func, args=(c, i,)) t.start() 上面的例子，每输入一次“yes”放行了一个线程。下面这个，可以选择一次放行几个线程。 #!/usr/bin/env python # -*- coding:utf-8 -*- import threading def run(n): con.acquire() con.wait() print(&quot;run the thread: %s&quot; %n) con.release() if __name__ == &apos;__main__&apos;: con = threading.Condition() for i in range(10): t = threading.Thread(target=run, args=(i,)) t.start() while True: inp = input(&apos;&gt;&gt;&gt;&apos;) if inp == &quot;q&quot;: break # 下面这三行是固定语法 con.acquire() con.notify(int(inp)) # 这个方法接收一个整数，表示让多少个线程通过 con.release() 1.3 全局解释器锁（GIL） 既然介绍了多线程和线程锁，那就不得不提及python的GIL，也就是全局解释器锁。在编程语言的世界，python因为GIL的问题广受诟病，因为它在解释器的层面限制了程序在同一时间只有一个线程被CPU实际执行，而不管你的程序里实际开了多少条线程。所以我们经常能发现，python中的多线程编程有时候效率还不如单线程，就是因为这个原因。那么，对于这个GIL，一些普遍的问题如下： 每种编程语言都有GIL吗？ 以python官方Cpython解释器为代表….其他语言好像未见。 为什么要有GIL？ 作为解释型语言，Python的解释器必须做到既安全又高效。我们都知道多线程编程会遇到的问题。解释器要留意的是避免在不同的线程操作内部共享的数据。同时它还要保证在管理用户线程时总是有最大化的计算资源。那么，不同线程同时访问时，数据的保护机制是怎样的呢？答案是解释器全局锁GIL。GIL对诸如当前线程状态和为垃圾回收而用的堆分配对象这样的东西的访问提供着保护。 为什么不能去掉GIL？ 首先，在早期的python解释器依赖较多的全局状态，传承下来，使得想要移除当今的GIL变得更加困难。其次，对于程序员而言，仅仅是想要理解它的实现就需要对操作系统设计、多线程编程、C语言、解释器设计和CPython解释器的实现有着非常彻底的理解。在1999年，针对Python1.5，一个“freethreading”补丁已经尝试移除GIL，用细粒度的锁来代替。然而，GIL的移除给单线程程序的执行速度带来了一定的负面影响。当用单线程执行时，速度大约降低了40%。虽然使用两个线程时在速度上得到了提高，但这个提高并没有随着核数的增加而线性增长。因此这个补丁没有被采纳。 另外，在python的不同解释器实现中，如PyPy就移除了GIL，其执行速度更快（不单单是去除GIL的原因）。然而，我们通常使用的CPython占有着统治地位的使用量，所以，你懂的。 在Python 3.2中实现了一个新的GIL，并且带着一些积极的结果。这是自1992年以来，GIL的一次最主要改变。旧的GIL通过对Python指令进行计数来确定何时放弃GIL。在新的GIL实现中，用一个固定的超时时间来指示当前的线程以放弃这个锁。在当前线程保持这个锁，且当第二个线程请求这个锁的时候，当前线程就会在5ms后被强制释放掉这个锁（这就是说，当前线程每5ms就要检查其是否需要释放这个锁）。当任务是可行的时候，这会使得线程间的切换更加可预测。 GIL对我们有什么影响？ 最大的影响是我们不能随意使用多线程。要区分任务场景。 在单核cpu情况下对性能的影响可以忽略不计，多线程多进程都差不多。在多核CPU时，多线程效率较低。GIL对单进程和多进程没有影响。 在实际使用中有什么好的建议？ 建议在IO密集型任务中使用多线程，在计算密集型任务中使用多进程。深入研究python的协程机制，你会有惊喜的。 更多的详细介绍和说明请参考下面的文献： 原文：Python’s Hardest Problem 译文：Python 最难的问题 1.4 定时器（Timer） 定时器，指定n秒后执行某操作。很简单但很使用的东西。 from threading import Timer def hello(): print(&quot;hello, world&quot;) t = Timer(1, hello) # 表示1秒后执行hello函数 t.start() 1.5 队列 通常而言，队列是一种先进先出的数据结构，与之对应的是堆栈这种后进先出的结构。但是在python中，它内置了一个queue模块，它不但提供普通的队列，还提供一些特殊的队列。具体如下： queue.Queue ：先进先出队列 queue.LifoQueue ：后进先出队列 queue.PriorityQueue ：优先级队列 queue.deque ：双向队列 1.5.1 Queue：先进先出队列 这是最常用也是最普遍的队列，先看一个例子。 import queue q = queue.Queue(5) q.put(11) q.put(22) q.put(33) print(q.get()) print(q.get()) print(q.get()) Queue类的参数和方法： maxsize 队列的最大元素个数，也就是queue.Queue(5)中的5。当队列内的元素达到这个值时，后来的元素默认会阻塞，等待队列腾出位置。 def __init__(self, maxsize=0): self.maxsize = maxsize self._init(maxsize) qsize() 获取当前队列中元素的个数，也就是队列的大小 empty() 判断当前队列是否为空，返回True或者False full() 判断当前队列是否已满，返回True或者False put(self, block=True, timeout=None) 往队列里放一个元素，默认是阻塞和无时间限制的。如果，block设置为False，则不阻塞，这时，如果队列是满的，放不进去，就会弹出异常。如果timeout设置为n秒，则会等待这个秒数后才put，如果put不进去则弹出异常。 get(self, block=True, timeout=None) 从队列里获取一个元素。参数和put是一样的意思。 join() 阻塞进程，直到所有任务完成，需要配合另一个方法task_done。 def join(self): with self.all_tasks_done: while self.unfinished_tasks: self.all_tasks_done.wait() task_done() 表示某个任务完成。每一条get语句后需要一条task_done。 import queue q = queue.Queue(5) q.put(11) q.put(22) print(q.get()) q.task_done() print(q.get()) q.task_done() q.join() 1.5.2 LifoQueue：后进先出队列 类似于“堆栈”，后进先出。也较常用。 import queue q = queue.LifoQueue() q.put(123) q.put(456) print(q.get()) 上述代码运行结果是：456 1.5.3 PriorityQueue：优先级队列 带有权重的队列，每个元素都是一个元组，前面的数字表示它的优先级，数字越小优先级越高，同样的优先级先进先出 q = queue.PriorityQueue() q.put((1,&quot;alex1&quot;)) q.put((1,&quot;alex2&quot;)) q.put((1,&quot;alex3&quot;)) q.put((3,&quot;alex3&quot;)) print(q.get()) 1.5.4 deque：双向队列 Queue和LifoQueue的“综合体”，双向进出。方法较多，使用复杂，慎用！ q = queue.deque() q.append(123) q.append(333) q.appendleft(456) q.pop() q.popleft() 1.6 生产者消费者模型 利用多线程和队列可以搭建一个生产者消费者模型，用于处理大并发的服务。 在并发编程中使用生产者和消费者模式能够解决绝大多数并发问题。该模式通过平衡生产线程和消费线程的工作能力来提高程序的整体处理数据的速度。 为什么要使用生产者和消费者模式 在线程世界里，生产者就是生产数据的线程，消费者就是消费数据的线程。在多线程开发当中，如果生产者处理速度很快，而消费者处理速度很慢，那么生产者就必须等待消费者处理完，才能继续生产数据。同样的道理，如果消费者的处理能力大于生产者，那么消费者就必须等待生产者。为了解决这个问题于是引入了生产者和消费者模式。 什么是生产者消费者模式 生产者消费者模式是通过一个容器来解决生产者和消费者的强耦合问题。生产者和消费者彼此之间不直接通讯，而通过阻塞队列来进行通讯，所以生产者生产完数据之后不用等待消费者处理，直接扔给阻塞队列，消费者不找生产者要数据，而是直接从阻塞队列里取，阻塞队列就相当于一个缓冲区，平衡了生产者和消费者的处理能力。 这个阻塞队列就是用来给生产者和消费者解耦的。纵观大多数设计模式，都会找一个第三者出来进行解耦，如工厂模式的第三者是工厂类，模板模式的第三者是模板类。在学习一些设计模式的过程中，如果先找到这个模式的第三者，能帮助我们快速熟悉一个设计模式。 以上摘自方腾飞的《聊聊并发——生产者消费者模式》 下面是一个简单的厨师做包子，顾客吃包子的例子。 #!/usr/bin/env python # -*- coding:utf-8 -*- # Author:Liu Jiang import time import queue import threading q = queue.Queue(10) def productor(i): while True: q.put(&quot;厨师 %s 做的包子！&quot;%i) time.sleep(2) def consumer(k): while True: print(&quot;顾客 %s 吃了一个 %s&quot;%(k,q.get())) time.sleep(1) for i in range(3): t = threading.Thread(target=productor,args=(i,)) t.start() for k in range(10): v = threading.Thread(target=consumer,args=(k,)) v.start() 1.7 线程池 在使用多线程处理任务时也不是线程越多越好，由于在切换线程的时候，需要切换上下文环境，依然会造成cpu的大量开销。为解决这个问题，线程池的概念被提出来了。预先创建好一个较为优化的数量的线程，让过来的任务立刻能够使用，就形成了线程池。在python中，没有内置的较好的线程池模块，需要自己实现或使用第三方模块。下面是一个简单的线程池： #!/usr/bin/env python # -*- coding:utf-8 -*- # Author:Liu Jiang import queue import time import threading class MyThreadPool: def __init__(self, maxsize=5): self.maxsize = maxsize self._q = queue.Queue(maxsize) for i in range(maxsize): self._q.put(threading.Thread) def get_thread(self): return self._q.get() def add_thread(self): self._q.put(threading.Thread) def task(i, pool): print(i) time.sleep(1) pool.add_thread() pool = MyThreadPool(5) for i in range(100): t = pool.get_thread() obj = t(target=task, args=(i,pool)) obj.start() 上面的例子是把线程类当做元素添加到队列内。实现方法比较糙，每个线程使用后就被抛弃，一开始就将线程开到满，因此性能较差。下面是一个相对好一点的例子，在这个例子中，队列里存放的不再是线程对象，而是任务对象，线程池也不是一开始就直接开辟所有线程，而是根据需要，逐步建立，直至池满。通过详细的代码注释，应该会有个清晰的理解。 #!/usr/bin/env python # -*- coding:utf-8 -*- &quot;&quot;&quot; 一个基于thread和queue的线程池，以任务为队列元素，动态创建线程，重复利用线程， 通过close和terminate方法关闭线程池。 &quot;&quot;&quot; import queue import threading import contextlib import time # 创建空对象,用于停止线程 StopEvent = object() def callback(status, result): &quot;&quot;&quot; 根据需要进行的回调函数，默认不执行。 :param status: action函数的执行状态 :param result: action函数的返回值 :return: &quot;&quot;&quot; pass def action(thread_name,arg): &quot;&quot;&quot; 真实的任务定义在这个函数里 :param thread_name: 执行该方法的线程名 :param arg: 该函数需要的参数 :return: &quot;&quot;&quot; # 模拟该函数执行了0.1秒 time.sleep(0.1) print(&quot;第%s个任务调用了线程 %s，并打印了这条信息！&quot; % (arg+1, thread_name)) class ThreadPool: def __init__(self, max_num, max_task_num=None): &quot;&quot;&quot; 初始化线程池 :param max_num: 线程池最大线程数量 :param max_task_num: 任务队列长度 &quot;&quot;&quot; # 如果提供了最大任务数的参数，则将队列的最大元素个数设置为这个值。 if max_task_num: self.q = queue.Queue(max_task_num) # 默认队列可接受无限多个的任务 else: self.q = queue.Queue() # 设置线程池最多可实例化的线程数 self.max_num = max_num # 任务取消标识 self.cancel = False # 任务中断标识 self.terminal = False # 已实例化的线程列表 self.generate_list = [] # 处于空闲状态的线程列表 self.free_list = [] def put(self, func, args, callback=None): &quot;&quot;&quot; 往任务队列里放入一个任务 :param func: 任务函数 :param args: 任务函数所需参数 :param callback: 任务执行失败或成功后执行的回调函数，回调函数有两个参数 1、任务函数执行状态；2、任务函数返回值（默认为None，即：不执行回调函数） :return: 如果线程池已经终止，则返回True否则None &quot;&quot;&quot; # 先判断标识，看看任务是否取消了 if self.cancel: return # 如果没有空闲的线程，并且已创建的线程的数量小于预定义的最大线程数，则创建新线程。 if len(self.free_list) == 0 and len(self.generate_list) self.max_num: self.generate_thread() # 构造任务参数元组，分别是调用的函数，该函数的参数，回调函数。 w = (func, args, callback,) # 将任务放入队列 self.q.put(w) def generate_thread(self): &quot;&quot;&quot; 创建一个线程 &quot;&quot;&quot; # 每个线程都执行call方法 t = threading.Thread(target=self.call) t.start() def call(self): &quot;&quot;&quot; 循环去获取任务函数并执行任务函数。在正常情况下，每个线程都保存生存状态， 直到获取线程终止的flag。 &quot;&quot;&quot; # 获取当前线程的名字 current_thread = threading.currentThread().getName() # 将当前线程的名字加入已实例化的线程列表中 self.generate_list.append(current_thread) # 从任务队列中获取一个任务 event = self.q.get() # 让获取的任务不是终止线程的标识对象时 while event != StopEvent: # 解析任务中封装的三个参数 func, arguments, callback = event # 抓取异常，防止线程因为异常退出 try: # 正常执行任务函数 result = func(current_thread, *arguments) success = True except Exception as e: # 当任务执行过程中弹出异常 result = None success = False # 如果有指定的回调函数 if callback is not None: # 执行回调函数，并抓取异常 try: callback(success, result) except Exception as e: pass # 当某个线程正常执行完一个任务时，先执行worker_state方法 with self.worker_state(self.free_list, current_thread): # 如果强制关闭线程的flag开启，则传入一个StopEvent元素 if self.terminal: event = StopEvent # 否则获取一个正常的任务，并回调worker_state方法的yield语句 else: # 从这里开始又是一个正常的任务循环 event = self.q.get() else: # 一旦发现任务是个终止线程的标识元素，将线程从已创建线程列表中删除 self.generate_list.remove(current_thread) def close(self): &quot;&quot;&quot; 执行完所有的任务后，让所有线程都停止的方法 &quot;&quot;&quot; # 设置flag self.cancel = True # 计算已创建线程列表中线程的个数，然后往任务队列里推送相同数量的终止线程的标识元素 full_size = len(self.generate_list) while full_size: self.q.put(StopEvent) full_size -= 1 def terminate(self): &quot;&quot;&quot; 在任务执行过程中，终止线程，提前退出。 &quot;&quot;&quot; self.terminal = True # 强制性的停止线程 while self.generate_list: self.q.put(StopEvent) # 该装饰器用于上下文管理 @contextlib.contextmanager def worker_state(self, state_list, worker_thread): &quot;&quot;&quot; 用于记录空闲的线程，或从空闲列表中取出线程处理任务 &quot;&quot;&quot; # 将当前线程，添加到空闲线程列表中 state_list.append(worker_thread) # 捕获异常 try: # 在此等待 yield finally: # 将线程从空闲列表中移除 state_list.remove(worker_thread) # 调用方式 if __name__ == &apos;__main__&apos;: # 创建一个最多包含5个线程的线程池 pool = ThreadPool(5) # 创建100个任务，让线程池进行处理 for i in range(100): pool.put(action, (i,), callback) # 等待一定时间，让线程执行任务 time.sleep(3) print(&quot;-&quot; * 50) print(&quot;33[32;0m任务停止之前线程池中有%s个线程，空闲的线程有%s个！33[0m&quot; % (len(pool.generate_list), len(pool.free_list))) # 正常关闭线程池 pool.close() print(&quot;任务执行完毕，正常退出！&quot;) # 强制关闭线程池 # pool.terminate() # print(&quot;强制停止任务！&quot;) 二、进程 在python中multiprocess模块提供了Process类，实现进程相关的功能。但是，由于它是基于fork机制的，因此不被windows平台支持。想要在windows中运行，必须使用if name == ‘main:的方式，显然这只能用于调试和学习，不能用于实际环境。 （PS：在这里我必须吐槽一下python的包、模块和类的组织结构。在multiprocess中你既可以import大写的Process，也可以import小写的process，这两者是完全不同的东西。这种情况在python中很多，新手容易傻傻分不清。） 下面是一个简单的多进程例子，你会发现Process的用法和Thread的用法几乎一模一样。 from multiprocessing import Process def foo(i): print(&quot;This is Process &quot;, i) if __name__ == &apos;__main__&apos;: for i in range(5): p = Process(target=foo, args=(i,)) p.start() 2.1 进程的数据共享 每个进程都有自己独立的数据空间，不同进程之间通常是不能共享数据，创建一个进程需要非常大的开销。 from multiprocessing import Process list_1 = [] def foo(i): list_1.append(i) print(&quot;This is Process &quot;, i,&quot; and list_1 is &quot;, list_1) if __name__ == &apos;__main__&apos;: for i in range(5): p = Process(target=foo, args=(i,)) p.start() print(&quot;The end of list_1:&quot;, list_1) 运行上面的代码，你会发现列表list_1在各个进程中只有自己的数据，完全无法共享。想要进程之间进行资源共享可以使用queues/Array/Manager这三个multiprocess模块提供的类。 2.1.1 使用Array共享数据 from multiprocessing import Process from multiprocessing import Array def Foo(i,temp): temp[0] += 100 for item in temp: print(i,&apos;-----&gt;&apos;,item) if __name__ == &apos;__main__&apos;: temp = Array(&apos;i&apos;, [11, 22, 33, 44]) for i in range(2): p = Process(target=Foo, args=(i,temp)) p.start() 对于Array数组类，括号内的“i”表示它内部的元素全部是int类型，而不是指字符i，列表内的元素可以预先指定，也可以指定列表长度。概括的来说就是Array类在实例化的时候就必须指定数组的数据类型和数组的大小，类似temp = Array(‘i’, 5)。对于数据类型有下面的表格对应： ‘c’: ctypes.c_char, ‘u’: ctypes.c_wchar, ‘b’: ctypes.c_byte, ‘B’: ctypes.c_ubyte, ‘h’: ctypes.c_short, ‘H’: ctypes.c_ushort, ‘i’: ctypes.c_int, ‘I’: ctypes.c_uint, ‘l’: ctypes.c_long, ‘L’: ctypes.c_ulong, ‘f’: ctypes.c_float, ‘d’: ctypes.c_double 2.1.2 使用Manager共享数据 from multiprocessing import Process,Manager def Foo(i,dic): dic[i] = 100+i print(dic.values()) if __name__ == &apos;__main__&apos;: manage = Manager() dic = manage.dict() for i in range(10): p = Process(target=Foo, args=(i,dic)) p.start() p.join() Manager比Array要好用一点，因为它可以同时保存多种类型的数据格式。 2.1.3 使用queues的Queue类共享数据 import multiprocessing from multiprocessing import Process from multiprocessing import queues def foo(i,arg): arg.put(i) print(&apos;The Process is &apos;, i, &quot;and the queue&apos;s size is &quot;, arg.qsize()) if __name__ == &quot;__main__&quot;: li = queues.Queue(20, ctx=multiprocessing) for i in range(10): p = Process(target=foo, args=(i,li,)) p.start() 这里就有点类似上面的队列了。从运行结果里，你还能发现数据共享中存在的脏数据问题。另外，比较悲催的是multiprocessing里还有一个Queue，一样能实现这个功能。 2.2 进程锁 为了防止和多线程一样的出现数据抢夺和脏数据的问题，同样需要设置进程锁。与threading类似，在multiprocessing里也有同名的锁类RLock, Lock, Event, Condition, Semaphore，连用法都是一样样的！（这个我喜欢） from multiprocessing import Process from multiprocessing import queues from multiprocessing import Array from multiprocessing import RLock, Lock, Event, Condition, Semaphore import multiprocessing import time def foo(i,lis,lc): lc.acquire() lis[0] = lis[0] - 1 time.sleep(1) print(&apos;say hi&apos;,lis[0]) lc.release() if __name__ == &quot;__main__&quot;: # li = [] li = Array(&apos;i&apos;, 1) li[0] = 10 lock = RLock() for i in range(10): p = Process(target=foo,args=(i,li,lock)) p.start() 2.3 进程池 既然有线程池，那必然也有进程池。但是，python给我们内置了一个进程池，不需要像线程池那样需要自定义，你只需要简单的from multiprocessing import Pool。 #!/usr/bin/env python # -*- coding:utf-8 -*- from multiprocessing import Pool import time def f1(args): time.sleep(1) print(args) if __name__ == &apos;__main__&apos;: p = Pool(5) for i in range(30): p.apply_async(func=f1, args= (i,)) p.close() # 等子进程执行完毕后关闭进程池 # time.sleep(2) # p.terminate() # 立刻关闭进程池 p.join() 进程池内部维护一个进程序列，当使用时，去进程池中获取一个进程，如果进程池序列中没有可供使用的进程，那么程序就会等待，直到进程池中有可用进程为止。进程池中有以下几个主要方法： apply：从进程池里取一个进程并执行 apply_async：apply的异步版本 terminate:立刻关闭进程池 join：主进程等待所有子进程执行完毕。必须在close或terminate之后。 close：等待所有进程结束后，才关闭进程池。 三、协程 线程和进程的操作是由程序触发系统接口，最后的执行者是系统，它本质上是操作系统提供的功能。而协程的操作则是程序员指定的，在python中通过yield，人为的实现并发处理。 协程存在的意义：对于多线程应用，CPU通过切片的方式来切换线程间的执行，线程切换时需要耗时。协程，则只使用一个线程，分解一个线程成为多个“微线程”，在一个线程中规定某个代码块的执行顺序。 协程的适用场景：当程序中存在大量不需要CPU的操作时（IO）。 在不需要自己“造轮子”的年代，同样有第三方模块为我们提供了高效的协程，这里介绍一下greenlet和gevent。本质上，gevent是对greenlet的高级封装，因此一般用它就行，这是一个相当高效的模块。 在使用它们之前，需要先安装，可以通过源码，也可以通过pip。 3.1 greenlet from greenlet import greenlet def test1(): print(12) gr2.switch() print(34) gr2.switch() def test2(): print(56) gr1.switch() print(78) gr1 = greenlet(test1) gr2 = greenlet(test2) gr1.switch() 实际上，greenlet就是通过switch方法在不同的任务之间进行切换。 3.2 gevent from gevent import monkey; monkey.patch_all() import gevent import requests def f(url): print(&apos;GET: %s&apos; % url) resp = requests.get(url) data = resp.text print(&apos;%d bytes received from %s.&apos; % (len(data), url)) gevent.joinall([ gevent.spawn(f, &apos;https://www.python.org/&apos;), gevent.spawn(f, &apos;https://www.yahoo.com/&apos;), gevent.spawn(f, &apos;https://github.com/&apos;), ]) 通过joinall将任务f和它的参数进行统一调度，实现单线程中的协程。代码封装层次很高，实际使用只需要了解它的几个主要方法即可。","categories":[{"name":"python","slug":"python","permalink":"http://yoursite.com/categories/python/"}],"tags":[{"name":"服务器","slug":"服务器","permalink":"http://yoursite.com/tags/服务器/"}]},{"title":"python进程和线程1","slug":"python进程和线程1","date":"2017-04-04T16:00:00.000Z","updated":"2018-03-08T14:54:47.427Z","comments":true,"path":"2017/04/05/python进程和线程1/","link":"","permalink":"http://yoursite.com/2017/04/05/python进程和线程1/","excerpt":"","text":"转自廖雪峰官网 我们介绍了多进程和多线程，这是实现多任务最常用的两种方式。现在，我们来讨论一下这两种方式的优缺点。 首先，要实现多任务，通常我们会设计Master-Worker模式，Master负责分配任务，Worker负责执行任务，因此，多任务环境下，通常是一个Master，多个Worker。 如果用多进程实现Master-Worker，主进程就是Master，其他进程就是Worker。 如果用多线程实现Master-Worker，主线程就是Master，其他线程就是Worker。 多进程模式最大的优点就是稳定性高，因为一个子进程崩溃了，不会影响主进程和其他子进程。（当然主进程挂了所有进程就全挂了，但是Master进程只负责分配任务，挂掉的概率低）著名的Apache最早就是采用多进程模式。 多进程模式的缺点是创建进程的代价大，在Unix/Linux系统下，用fork调用还行，在Windows下创建进程开销巨大。另外，操作系统能同时运行的进程数也是有限的，在内存和CPU的限制下，如果有几千个进程同时运行，操作系统连调度都会成问题。 多线程模式通常比多进程快一点，但是也快不到哪去，而且，多线程模式致命的缺点就是任何一个线程挂掉都可能直接造成整个进程崩溃，因为所有线程共享进程的内存。在Windows上，如果一个线程执行的代码出了问题，你经常可以看到这样的提示：“该程序执行了非法操作，即将关闭”，其实往往是某个线程出了问题，但是操作系统会强制结束整个进程。 在Windows下，多线程的效率比多进程要高，所以微软的IIS服务器默认采用多线程模式。由于多线程存在稳定性的问题，IIS的稳定性就不如Apache。为了缓解这个问题，IIS和Apache现在又有多进程+多线程的混合模式，真是把问题越搞越复杂。 线程切换无论是多进程还是多线程，只要数量一多，效率肯定上不去，为什么呢？ 我们打个比方，假设你不幸正在准备中考，每天晚上需要做语文、数学、英语、物理、化学这5科的作业，每项作业耗时1小时。 如果你先花1小时做语文作业，做完了，再花1小时做数学作业，这样，依次全部做完，一共花5小时，这种方式称为单任务模型，或者批处理任务模型。 假设你打算切换到多任务模型，可以先做1分钟语文，再切换到数学作业，做1分钟，再切换到英语，以此类推，只要切换速度足够快，这种方式就和单核CPU执行多任务是一样的了，以幼儿园小朋友的眼光来看，你就正在同时写5科作业。 但是，切换作业是有代价的，比如从语文切到数学，要先收拾桌子上的语文书本、钢笔（这叫保存现场），然后，打开数学课本、找出圆规直尺（这叫准备新环境），才能开始做数学作业。操作系统在切换进程或者线程时也是一样的，它需要先保存当前执行的现场环境（CPU寄存器状态、内存页等），然后，把新任务的执行环境准备好（恢复上次的寄存器状态，切换内存页等），才能开始执行。这个切换过程虽然很快，但是也需要耗费时间。如果有几千个任务同时进行，操作系统可能就主要忙着切换任务，根本没有多少时间去执行任务了，这种情况最常见的就是硬盘狂响，点窗口无反应，系统处于假死状态。 所以，多任务一旦多到一个限度，就会消耗掉系统所有的资源，结果效率急剧下降，所有任务都做不好。 计算密集型 vs. IO密集型是否采用多任务的第二个考虑是任务的类型。我们可以把任务分为计算密集型和IO密集型。 计算密集型任务的特点是要进行大量的计算，消耗CPU资源，比如计算圆周率、对视频进行高清解码等等，全靠CPU的运算能力。这种计算密集型任务虽然也可以用多任务完成，但是任务越多，花在任务切换的时间就越多，CPU执行任务的效率就越低，所以，要最高效地利用CPU，计算密集型任务同时进行的数量应当等于CPU的核心数。 计算密集型任务由于主要消耗CPU资源，因此，代码运行效率至关重要。Python这样的脚本语言运行效率很低，完全不适合计算密集型任务。对于计算密集型任务，最好用C语言编写。 第二种任务的类型是IO密集型，涉及到网络、磁盘IO的任务都是IO密集型任务，这类任务的特点是CPU消耗很少，任务的大部分时间都在等待IO操作完成（因为IO的速度远远低于CPU和内存的速度）。对于IO密集型任务，任务越多，CPU效率越高，但也有一个限度。常见的大部分任务都是IO密集型任务，比如Web应用。 IO密集型任务执行期间，99%的时间都花在IO上，花在CPU上的时间很少，因此，用运行速度极快的C语言替换用Python这样运行速度极低的脚本语言，完全无法提升运行效率。对于IO密集型任务，最合适的语言就是开发效率最高（代码量最少）的语言，脚本语言是首选，C语言最差。 异步IO考虑到CPU和IO之间巨大的速度差异，一个任务在执行的过程中大部分时间都在等待IO操作，单进程单线程模型会导致别的任务无法并行执行，因此，我们才需要多进程模型或者多线程模型来支持多任务并发执行。 现代操作系统对IO操作已经做了巨大的改进，最大的特点就是支持异步IO。如果充分利用操作系统提供的异步IO支持，就可以用单进程单线程模型来执行多任务，这种全新的模型称为事件驱动模型，Nginx就是支持异步IO的Web服务器，它在单核CPU上采用单进程模型就可以高效地支持多任务。在多核CPU上，可以运行多个进程（数量与CPU核心数相同），充分利用多核CPU。由于系统总的进程数量十分有限，因此操作系统调度非常高效。用异步IO编程模型来实现多任务是一个主要的趋势。 对应到Python语言，单进程的异步编程模型称为协程，有了协程的支持，就可以基于事件驱动编写高效的多任务程序。我们会在后面讨论如何编写协程。","categories":[{"name":"python","slug":"python","permalink":"http://yoursite.com/categories/python/"}],"tags":[{"name":"进程 线程","slug":"进程-线程","permalink":"http://yoursite.com/tags/进程-线程/"}]},{"title":"Python之线程、进程和协程2","slug":"Python之线程、进程和协程2","date":"2017-03-30T16:00:00.000Z","updated":"2018-03-06T13:03:41.358Z","comments":true,"path":"2017/03/31/Python之线程、进程和协程2/","link":"","permalink":"http://yoursite.com/2017/03/31/Python之线程、进程和协程2/","excerpt":"","text":"原文出处： 银河系1234目录： 引言一、线程1.1 普通的多线程 1.2 自定义线程类 1.3 线程锁 1.3.1 未使用锁 1.3.2 普通锁Lock和RLock 1.3.3 信号量(Semaphore) 1.3.4 事件(Event) 1.3.5 条件(condition) 1.3 全局解释器锁（GIL） 1.4 定时器（Timer） 1.5 队列 1.5.1 Queue：先进先出队列 1.5.2 LifoQueue：后进先出队列 1.5.3 PriorityQueue：优先级队列 1.5.4 deque：双向队列 1.6 生产者消费者模型 1.7 线程池 二、进程2.1 进程的数据共享 2.1.1 使用Array共享数据 2.1.2 使用Manager共享数据 2.1.3 使用queues的Queue类共享数据 2.2 进程锁 2.3 进程池 三、协程3.1 greenlet3.2 gevent 引言解释器环境：python3.5.1我们都知道python网络编程的两大必学模块socket和socketserver，其中的socketserver是一个支持IO多路复用和多线程、多进程的模块。一般我们在socketserver服务端代码中都会写这么一句： server = socketserver.ThreadingTCPServer(settings.IP_PORT, MyServer) ThreadingTCPServer这个类是一个支持多线程和TCP协议的socketserver，它的继承关系是这样的： class ThreadingTCPServer(ThreadingMixIn, TCPServer): pass 右边的TCPServer实际上是它主要的功能父类，而左边的ThreadingMixIn则是实现了多线程的类，它自己本身则没有任何代码。 MixIn在python的类命名中，很常见，一般被称为“混入”，戏称“乱入”，通常为了某种重要功能被子类继承。 class ThreadingMixIn: daemon_threads = False def process_request_thread(self, request, client_address): try: self.finish_request(request, client_address) self.shutdown_request(request) except: self.handle_error(request, client_address) self.shutdown_request(request) def process_request(self, request, client_address): t = threading.Thread(target = self.process_request_thread, args = (request, client_address)) t.daemon = self.daemon_threads t.start() 在ThreadingMixIn类中，其实就定义了一个属性，两个方法。在process_request方法中实际调用的正是python内置的多线程模块threading。这个模块是python中所有多线程的基础，socketserver本质上也是利用了这个模块。 一、线程线程，有时被称为轻量级进程(Lightweight Process，LWP），是程序执行流的最小单元。一个标准的线程由线程ID，当前指令指针(PC），寄存器集合和堆栈组成。另外，线程是进程中的一个实体，是被系统独立调度和分派的基本单位，线程自己不独立拥有系统资源，但它可与同属一个进程的其它线程共享该进程所拥有的全部资源。一个线程可以创建和撤消另一个线程，同一进程中的多个线程之间可以并发执行。由于线程之间的相互制约，致使线程在运行中呈现出间断性。线程也有就绪、阻塞和运行三种基本状态。就绪状态是指线程具备运行的所有条件，逻辑上可以运行，在等待处理机；运行状态是指线程占有处理机正在运行；阻塞状态是指线程在等待一个事件（如某个信号量），逻辑上不可执行。每一个应用程序都至少有一个进程和一个线程。线程是程序中一个单一的顺序控制流程。在单个程序中同时运行多个线程完成不同的被划分成一块一块的工作，称为多线程。以上那一段，可以不用看！举个例子，厂家要生产某个产品，在它的生产基地建设了很多厂房，每个厂房内又有多条流水生产线。所有厂房配合将整个产品生产出来，某个厂房内的所有流水线将这个厂房负责的产品部分生产出来。每个厂房拥有自己的材料库，厂房内的生产线共享这些材料。而每一个厂家要实现生产必须拥有至少一个厂房一条生产线。那么这个厂家就是某个应用程序；每个厂房就是一个进程；每条生产线都是一个线程。 1.1 普通的多线程在python中，threading模块提供线程的功能。通过它，我们可以轻易的在进程中创建多个线程。下面是个例子： import threading import time def show(arg): time.sleep(1) print(&apos;thread&apos;+str(arg)) for i in range(10): t = threading.Thread(target=show, args=(i,)) t.start() print(&apos;main thread stop&apos;) 上述代码创建了10个“前台”线程，然后控制器就交给了CPU，CPU根据指定算法进行调度，分片执行指令。下面是Thread类的主要方法： start 线程准备就绪，等待CPU调度 setName 为线程设置名称 getName 获取线程名称 setDaemon 设置为后台线程或前台线程（默认是False，前台线程） 如果是后台线程，主线程执行过程中，后台线程也在进行，主线程执行完毕后，后台线程不论成功与否，均停止。如果是前台线程，主线程执行过程中，前台线程也在进行，主线程执行完毕后，等待前台线程也执行完成后，程序停止。 join 该方法非常重要。它的存在是告诉主线程，必须在这个位置等待子线程执行完毕后，才继续进行主线程的后面的代码。但是当setDaemon为True时，join方法是无效的。 run 线程被cpu调度后自动执行线程对象的run方法 1.2 自定义线程类 对于threading模块中的Thread类，本质上是执行了它的run方法。因此可以自定义线程类，让它继承Thread类，然后重写run方法。 import threading class MyThreading(threading.Thread): def __init__(self,func,arg): super(MyThreading,self).__init__() self.func = func self.arg = arg def run(self): self.func(self.arg) def f1(args): print(args) obj = MyThreading(f1, 123) obj.start() 1.3 线程锁 CPU执行任务时，在线程之间是进行随机调度的，并且每个线程可能只执行n条代码后就转而执行另外一条线程。由于在一个进程中的多个线程之间是共享资源和数据的，这就容易造成资源抢夺或脏数据，于是就有了锁的概念，限制某一时刻只有一个线程能访问某个指定的数据。 1.3.1 未使用锁 #!/usr/bin/env python # -*- coding:utf-8 -*- import threading import time NUM = 0 def show(): global NUM NUM += 1 name = t.getName() time.sleep(1) # 注意，这行语句的位置很重要，必须在NUM被修改后，否则观察不到脏数据的现象。 print(name, &quot;执行完毕后，NUM的值为： &quot;, NUM) for i in range(10): t = threading.Thread(target=show) t.start() print(&apos;main thread stop&apos;) 上述代码运行后，结果如下： main thread stop Thread-1 执行完毕后，NUM的值为： 10 Thread-2 执行完毕后，NUM的值为： 10 Thread-4 执行完毕后，NUM的值为： 10 Thread-9 执行完毕后，NUM的值为： 10 Thread-3 执行完毕后，NUM的值为： 10 Thread-6 执行完毕后，NUM的值为： 10 Thread-8 执行完毕后，NUM的值为： 10 Thread-7 执行完毕后，NUM的值为： 10 Thread-5 执行完毕后，NUM的值为： 10 Thread-10 执行完毕后，NUM的值为： 10 由此可见，由于线程同时访问一个数据，产生了错误的结果。为了解决这个问题，python在threading模块中定义了几种线程锁类，分别是： Lock 普通锁（不可嵌套） RLock 普通锁（可嵌套）常用 Semaphore 信号量 event 事件 condition 条件 1.3.2 普通锁Lock和RLock 类名：Lock或RLock 普通锁，也叫互斥锁，是独占的，同一时刻只有一个线程被放行。 import time import threading NUM = 10 def func(lock): global NUM lock.acquire() # 让锁开始起作用 NUM -= 1 time.sleep(1) print(NUM) lock.release() # 释放锁 lock = threading.Lock() # 实例化一个锁对象 for i in range(10): t = threading.Thread(target=func, args=(lock,)) # 记得把锁当作参数传递给func参数 t.start() 以上是threading模块的Lock类，它不支持嵌套锁。RLcok类的用法和Lock一模一样，但它支持嵌套，因此我们一般直接使用RLcok类。 1.3.3 信号量(Semaphore) 类名：BoundedSemaphore 这种锁允许一定数量的线程同时更改数据，它不是互斥锁。比如地铁安检，排队人很多，工作人员只允许一定数量的人进入安检区，其它的人继续排队。 #!/usr/bin/env python # -*- coding:utf-8 -*- import time import threading def run(n): semaphore.acquire() print(&quot;run the thread: %s&quot; % n) time.sleep(1) semaphore.release() num = 0 semaphore = threading.BoundedSemaphore(5) # 最多允许5个线程同时运行 for i in range(20): t = threading.Thread(target=run, args=(i,)) t.start() 1.3.4 事件(Event) 类名：Event 事件主要提供了三个方法 set、wait、clear。 事件机制：全局定义了一个“Flag”，如果“Flag”的值为False，那么当程序执行wait方法时就会阻塞，如果“Flag”值为True，那么wait方法时便不再阻塞。这种锁，类似交通红绿灯（默认是红灯），它属于在红灯的时候一次性阻挡所有线程，在绿灯的时候，一次性放行所有的排队中的线程。 clear：将“Flag”设置为False set：将“Flag”设置为True import threading def func(e,i): print(i) e.wait() # 检测当前event是什么状态，如果是红灯，则阻塞，如果是绿灯则继续往下执行。默认是红灯。 print(i+100) event = threading.Event() for i in range(10): t = threading.Thread(target=func, args=(event, i)) t.start() event.clear() # 主动将状态设置为红灯 inp = input(&quot;&gt;&gt;&gt;&quot;) if inp == &quot;1&quot;: event.set() # 主动将状态设置为绿灯 1.3.5 条件(condition) 类名：Condition 该机制会使得线程等待，只有满足某条件时，才释放n个线程。 import threading def condition(): ret = False r = input(&quot;&gt;&gt;&gt;&quot;) if r == &quot;yes&quot;: ret = True return ret def func(conn, i): print(i) conn.acquire() conn.wait_for(condition) # 这个方法接受一个函数的返回值 print(i+100) conn.release() c = threading.Condition() for i in range(10): t = threading.Thread(target=func, args=(c, i,)) t.start() 上面的例子，每输入一次“yes”放行了一个线程。下面这个，可以选择一次放行几个线程。 #!/usr/bin/env python # -*- coding:utf-8 -*- import threading def run(n): con.acquire() con.wait() print(&quot;run the thread: %s&quot; %n) con.release() if __name__ == &apos;__main__&apos;: con = threading.Condition() for i in range(10): t = threading.Thread(target=run, args=(i,)) t.start() while True: inp = input(&apos;&gt;&gt;&gt;&apos;) if inp == &quot;q&quot;: break # 下面这三行是固定语法 con.acquire() con.notify(int(inp)) # 这个方法接收一个整数，表示让多少个线程通过 con.release() 1.3 全局解释器锁（GIL） 既然介绍了多线程和线程锁，那就不得不提及python的GIL，也就是全局解释器锁。在编程语言的世界，python因为GIL的问题广受诟病，因为它在解释器的层面限制了程序在同一时间只有一个线程被CPU实际执行，而不管你的程序里实际开了多少条线程。所以我们经常能发现，python中的多线程编程有时候效率还不如单线程，就是因为这个原因。那么，对于这个GIL，一些普遍的问题如下： 每种编程语言都有GIL吗？ 以python官方Cpython解释器为代表….其他语言好像未见。 为什么要有GIL？ 作为解释型语言，Python的解释器必须做到既安全又高效。我们都知道多线程编程会遇到的问题。解释器要留意的是避免在不同的线程操作内部共享的数据。同时它还要保证在管理用户线程时总是有最大化的计算资源。那么，不同线程同时访问时，数据的保护机制是怎样的呢？答案是解释器全局锁GIL。GIL对诸如当前线程状态和为垃圾回收而用的堆分配对象这样的东西的访问提供着保护。 为什么不能去掉GIL？ 首先，在早期的python解释器依赖较多的全局状态，传承下来，使得想要移除当今的GIL变得更加困难。其次，对于程序员而言，仅仅是想要理解它的实现就需要对操作系统设计、多线程编程、C语言、解释器设计和CPython解释器的实现有着非常彻底的理解。在1999年，针对Python1.5，一个“freethreading”补丁已经尝试移除GIL，用细粒度的锁来代替。然而，GIL的移除给单线程程序的执行速度带来了一定的负面影响。当用单线程执行时，速度大约降低了40%。虽然使用两个线程时在速度上得到了提高，但这个提高并没有随着核数的增加而线性增长。因此这个补丁没有被采纳。 另外，在python的不同解释器实现中，如PyPy就移除了GIL，其执行速度更快（不单单是去除GIL的原因）。然而，我们通常使用的CPython占有着统治地位的使用量，所以，你懂的。 在Python 3.2中实现了一个新的GIL，并且带着一些积极的结果。这是自1992年以来，GIL的一次最主要改变。旧的GIL通过对Python指令进行计数来确定何时放弃GIL。在新的GIL实现中，用一个固定的超时时间来指示当前的线程以放弃这个锁。在当前线程保持这个锁，且当第二个线程请求这个锁的时候，当前线程就会在5ms后被强制释放掉这个锁（这就是说，当前线程每5ms就要检查其是否需要释放这个锁）。当任务是可行的时候，这会使得线程间的切换更加可预测。 GIL对我们有什么影响？ 最大的影响是我们不能随意使用多线程。要区分任务场景。 在单核cpu情况下对性能的影响可以忽略不计，多线程多进程都差不多。在多核CPU时，多线程效率较低。GIL对单进程和多进程没有影响。 在实际使用中有什么好的建议？ 建议在IO密集型任务中使用多线程，在计算密集型任务中使用多进程。深入研究python的协程机制，你会有惊喜的。 更多的详细介绍和说明请参考下面的文献： 原文：Python’s Hardest Problem 译文：Python 最难的问题 1.4 定时器（Timer） 定时器，指定n秒后执行某操作。很简单但很使用的东西。 from threading import Timer def hello(): print(&quot;hello, world&quot;) t = Timer(1, hello) # 表示1秒后执行hello函数 t.start() 1.5 队列 通常而言，队列是一种先进先出的数据结构，与之对应的是堆栈这种后进先出的结构。但是在python中，它内置了一个queue模块，它不但提供普通的队列，还提供一些特殊的队列。具体如下： queue.Queue ：先进先出队列 queue.LifoQueue ：后进先出队列 queue.PriorityQueue ：优先级队列 queue.deque ：双向队列 1.5.1 Queue：先进先出队列 这是最常用也是最普遍的队列，先看一个例子。 import queue q = queue.Queue(5) q.put(11) q.put(22) q.put(33) print(q.get()) print(q.get()) print(q.get()) Queue类的参数和方法： maxsize 队列的最大元素个数，也就是queue.Queue(5)中的5。当队列内的元素达到这个值时，后来的元素默认会阻塞，等待队列腾出位置。 def __init__(self, maxsize=0): self.maxsize = maxsize self._init(maxsize) qsize() 获取当前队列中元素的个数，也就是队列的大小 empty() 判断当前队列是否为空，返回True或者False full() 判断当前队列是否已满，返回True或者False put(self, block=True, timeout=None) 往队列里放一个元素，默认是阻塞和无时间限制的。如果，block设置为False，则不阻塞，这时，如果队列是满的，放不进去，就会弹出异常。如果timeout设置为n秒，则会等待这个秒数后才put，如果put不进去则弹出异常。 get(self, block=True, timeout=None) 从队列里获取一个元素。参数和put是一样的意思。 join() 阻塞进程，直到所有任务完成，需要配合另一个方法task_done。 def join(self): with self.all_tasks_done: while self.unfinished_tasks: self.all_tasks_done.wait() task_done() 表示某个任务完成。每一条get语句后需要一条task_done。 import queue q = queue.Queue(5) q.put(11) q.put(22) print(q.get()) q.task_done() print(q.get()) q.task_done() q.join() 1.5.2 LifoQueue：后进先出队列 类似于“堆栈”，后进先出。也较常用。 import queue q = queue.LifoQueue() q.put(123) q.put(456) print(q.get()) 上述代码运行结果是：456 1.5.3 PriorityQueue：优先级队列 带有权重的队列，每个元素都是一个元组，前面的数字表示它的优先级，数字越小优先级越高，同样的优先级先进先出 q = queue.PriorityQueue() q.put((1,&quot;alex1&quot;)) q.put((1,&quot;alex2&quot;)) q.put((1,&quot;alex3&quot;)) q.put((3,&quot;alex3&quot;)) print(q.get()) 1.5.4 deque：双向队列 Queue和LifoQueue的“综合体”，双向进出。方法较多，使用复杂，慎用！ q = queue.deque() q.append(123) q.append(333) q.appendleft(456) q.pop() q.popleft() 1.6 生产者消费者模型 利用多线程和队列可以搭建一个生产者消费者模型，用于处理大并发的服务。 在并发编程中使用生产者和消费者模式能够解决绝大多数并发问题。该模式通过平衡生产线程和消费线程的工作能力来提高程序的整体处理数据的速度。 为什么要使用生产者和消费者模式 在线程世界里，生产者就是生产数据的线程，消费者就是消费数据的线程。在多线程开发当中，如果生产者处理速度很快，而消费者处理速度很慢，那么生产者就必须等待消费者处理完，才能继续生产数据。同样的道理，如果消费者的处理能力大于生产者，那么消费者就必须等待生产者。为了解决这个问题于是引入了生产者和消费者模式。 什么是生产者消费者模式 生产者消费者模式是通过一个容器来解决生产者和消费者的强耦合问题。生产者和消费者彼此之间不直接通讯，而通过阻塞队列来进行通讯，所以生产者生产完数据之后不用等待消费者处理，直接扔给阻塞队列，消费者不找生产者要数据，而是直接从阻塞队列里取，阻塞队列就相当于一个缓冲区，平衡了生产者和消费者的处理能力。 这个阻塞队列就是用来给生产者和消费者解耦的。纵观大多数设计模式，都会找一个第三者出来进行解耦，如工厂模式的第三者是工厂类，模板模式的第三者是模板类。在学习一些设计模式的过程中，如果先找到这个模式的第三者，能帮助我们快速熟悉一个设计模式。 以上摘自方腾飞的《聊聊并发——生产者消费者模式》 下面是一个简单的厨师做包子，顾客吃包子的例子。 #!/usr/bin/env python # -*- coding:utf-8 -*- # Author:Liu Jiang import time import queue import threading q = queue.Queue(10) def productor(i): while True: q.put(&quot;厨师 %s 做的包子！&quot;%i) time.sleep(2) def consumer(k): while True: print(&quot;顾客 %s 吃了一个 %s&quot;%(k,q.get())) time.sleep(1) for i in range(3): t = threading.Thread(target=productor,args=(i,)) t.start() for k in range(10): v = threading.Thread(target=consumer,args=(k,)) v.start() 1.7 线程池 在使用多线程处理任务时也不是线程越多越好，由于在切换线程的时候，需要切换上下文环境，依然会造成cpu的大量开销。为解决这个问题，线程池的概念被提出来了。预先创建好一个较为优化的数量的线程，让过来的任务立刻能够使用，就形成了线程池。在python中，没有内置的较好的线程池模块，需要自己实现或使用第三方模块。下面是一个简单的线程池： #!/usr/bin/env python # -*- coding:utf-8 -*- # Author:Liu Jiang import queue import time import threading class MyThreadPool: def __init__(self, maxsize=5): self.maxsize = maxsize self._q = queue.Queue(maxsize) for i in range(maxsize): self._q.put(threading.Thread) def get_thread(self): return self._q.get() def add_thread(self): self._q.put(threading.Thread) def task(i, pool): print(i) time.sleep(1) pool.add_thread() pool = MyThreadPool(5) for i in range(100): t = pool.get_thread() obj = t(target=task, args=(i,pool)) obj.start() 上面的例子是把线程类当做元素添加到队列内。实现方法比较糙，每个线程使用后就被抛弃，一开始就将线程开到满，因此性能较差。下面是一个相对好一点的例子，在这个例子中，队列里存放的不再是线程对象，而是任务对象，线程池也不是一开始就直接开辟所有线程，而是根据需要，逐步建立，直至池满。通过详细的代码注释，应该会有个清晰的理解。 #!/usr/bin/env python # -*- coding:utf-8 -*- &quot;&quot;&quot; 一个基于thread和queue的线程池，以任务为队列元素，动态创建线程，重复利用线程， 通过close和terminate方法关闭线程池。 &quot;&quot;&quot; import queue import threading import contextlib import time # 创建空对象,用于停止线程 StopEvent = object() def callback(status, result): &quot;&quot;&quot; 根据需要进行的回调函数，默认不执行。 :param status: action函数的执行状态 :param result: action函数的返回值 :return: &quot;&quot;&quot; pass def action(thread_name,arg): &quot;&quot;&quot; 真实的任务定义在这个函数里 :param thread_name: 执行该方法的线程名 :param arg: 该函数需要的参数 :return: &quot;&quot;&quot; # 模拟该函数执行了0.1秒 time.sleep(0.1) print(&quot;第%s个任务调用了线程 %s，并打印了这条信息！&quot; % (arg+1, thread_name)) class ThreadPool: def __init__(self, max_num, max_task_num=None): &quot;&quot;&quot; 初始化线程池 :param max_num: 线程池最大线程数量 :param max_task_num: 任务队列长度 &quot;&quot;&quot; # 如果提供了最大任务数的参数，则将队列的最大元素个数设置为这个值。 if max_task_num: self.q = queue.Queue(max_task_num) # 默认队列可接受无限多个的任务 else: self.q = queue.Queue() # 设置线程池最多可实例化的线程数 self.max_num = max_num # 任务取消标识 self.cancel = False # 任务中断标识 self.terminal = False # 已实例化的线程列表 self.generate_list = [] # 处于空闲状态的线程列表 self.free_list = [] def put(self, func, args, callback=None): &quot;&quot;&quot; 往任务队列里放入一个任务 :param func: 任务函数 :param args: 任务函数所需参数 :param callback: 任务执行失败或成功后执行的回调函数，回调函数有两个参数 1、任务函数执行状态；2、任务函数返回值（默认为None，即：不执行回调函数） :return: 如果线程池已经终止，则返回True否则None &quot;&quot;&quot; # 先判断标识，看看任务是否取消了 if self.cancel: return # 如果没有空闲的线程，并且已创建的线程的数量小于预定义的最大线程数，则创建新线程。 if len(self.free_list) == 0 and len(self.generate_list) self.max_num: self.generate_thread() # 构造任务参数元组，分别是调用的函数，该函数的参数，回调函数。 w = (func, args, callback,) # 将任务放入队列 self.q.put(w) def generate_thread(self): &quot;&quot;&quot; 创建一个线程 &quot;&quot;&quot; # 每个线程都执行call方法 t = threading.Thread(target=self.call) t.start() def call(self): &quot;&quot;&quot; 循环去获取任务函数并执行任务函数。在正常情况下，每个线程都保存生存状态， 直到获取线程终止的flag。 &quot;&quot;&quot; # 获取当前线程的名字 current_thread = threading.currentThread().getName() # 将当前线程的名字加入已实例化的线程列表中 self.generate_list.append(current_thread) # 从任务队列中获取一个任务 event = self.q.get() # 让获取的任务不是终止线程的标识对象时 while event != StopEvent: # 解析任务中封装的三个参数 func, arguments, callback = event # 抓取异常，防止线程因为异常退出 try: # 正常执行任务函数 result = func(current_thread, *arguments) success = True except Exception as e: # 当任务执行过程中弹出异常 result = None success = False # 如果有指定的回调函数 if callback is not None: # 执行回调函数，并抓取异常 try: callback(success, result) except Exception as e: pass # 当某个线程正常执行完一个任务时，先执行worker_state方法 with self.worker_state(self.free_list, current_thread): # 如果强制关闭线程的flag开启，则传入一个StopEvent元素 if self.terminal: event = StopEvent # 否则获取一个正常的任务，并回调worker_state方法的yield语句 else: # 从这里开始又是一个正常的任务循环 event = self.q.get() else: # 一旦发现任务是个终止线程的标识元素，将线程从已创建线程列表中删除 self.generate_list.remove(current_thread) def close(self): &quot;&quot;&quot; 执行完所有的任务后，让所有线程都停止的方法 &quot;&quot;&quot; # 设置flag self.cancel = True # 计算已创建线程列表中线程的个数，然后往任务队列里推送相同数量的终止线程的标识元素 full_size = len(self.generate_list) while full_size: self.q.put(StopEvent) full_size -= 1 def terminate(self): &quot;&quot;&quot; 在任务执行过程中，终止线程，提前退出。 &quot;&quot;&quot; self.terminal = True # 强制性的停止线程 while self.generate_list: self.q.put(StopEvent) # 该装饰器用于上下文管理 @contextlib.contextmanager def worker_state(self, state_list, worker_thread): &quot;&quot;&quot; 用于记录空闲的线程，或从空闲列表中取出线程处理任务 &quot;&quot;&quot; # 将当前线程，添加到空闲线程列表中 state_list.append(worker_thread) # 捕获异常 try: # 在此等待 yield finally: # 将线程从空闲列表中移除 state_list.remove(worker_thread) # 调用方式 if __name__ == &apos;__main__&apos;: # 创建一个最多包含5个线程的线程池 pool = ThreadPool(5) # 创建100个任务，让线程池进行处理 for i in range(100): pool.put(action, (i,), callback) # 等待一定时间，让线程执行任务 time.sleep(3) print(&quot;-&quot; * 50) print(&quot;33[32;0m任务停止之前线程池中有%s个线程，空闲的线程有%s个！33[0m&quot; % (len(pool.generate_list), len(pool.free_list))) # 正常关闭线程池 pool.close() print(&quot;任务执行完毕，正常退出！&quot;) # 强制关闭线程池 # pool.terminate() # print(&quot;强制停止任务！&quot;) 二、进程 在python中multiprocess模块提供了Process类，实现进程相关的功能。但是，由于它是基于fork机制的，因此不被windows平台支持。想要在windows中运行，必须使用if name == ‘main:的方式，显然这只能用于调试和学习，不能用于实际环境。 （PS：在这里我必须吐槽一下python的包、模块和类的组织结构。在multiprocess中你既可以import大写的Process，也可以import小写的process，这两者是完全不同的东西。这种情况在python中很多，新手容易傻傻分不清。） 下面是一个简单的多进程例子，你会发现Process的用法和Thread的用法几乎一模一样。 from multiprocessing import Process def foo(i): print(&quot;This is Process &quot;, i) if __name__ == &apos;__main__&apos;: for i in range(5): p = Process(target=foo, args=(i,)) p.start() 2.1 进程的数据共享 每个进程都有自己独立的数据空间，不同进程之间通常是不能共享数据，创建一个进程需要非常大的开销。 from multiprocessing import Process list_1 = [] def foo(i): list_1.append(i) print(&quot;This is Process &quot;, i,&quot; and list_1 is &quot;, list_1) if __name__ == &apos;__main__&apos;: for i in range(5): p = Process(target=foo, args=(i,)) p.start() print(&quot;The end of list_1:&quot;, list_1) 运行上面的代码，你会发现列表list_1在各个进程中只有自己的数据，完全无法共享。想要进程之间进行资源共享可以使用queues/Array/Manager这三个multiprocess模块提供的类。 2.1.1 使用Array共享数据 from multiprocessing import Process from multiprocessing import Array def Foo(i,temp): temp[0] += 100 for item in temp: print(i,&apos;-----&gt;&apos;,item) if __name__ == &apos;__main__&apos;: temp = Array(&apos;i&apos;, [11, 22, 33, 44]) for i in range(2): p = Process(target=Foo, args=(i,temp)) p.start() 对于Array数组类，括号内的“i”表示它内部的元素全部是int类型，而不是指字符i，列表内的元素可以预先指定，也可以指定列表长度。概括的来说就是Array类在实例化的时候就必须指定数组的数据类型和数组的大小，类似temp = Array(‘i’, 5)。对于数据类型有下面的表格对应： ‘c’: ctypes.c_char, ‘u’: ctypes.c_wchar, ‘b’: ctypes.c_byte, ‘B’: ctypes.c_ubyte, ‘h’: ctypes.c_short, ‘H’: ctypes.c_ushort, ‘i’: ctypes.c_int, ‘I’: ctypes.c_uint, ‘l’: ctypes.c_long, ‘L’: ctypes.c_ulong, ‘f’: ctypes.c_float, ‘d’: ctypes.c_double 2.1.2 使用Manager共享数据 from multiprocessing import Process,Manager def Foo(i,dic): dic[i] = 100+i print(dic.values()) if __name__ == &apos;__main__&apos;: manage = Manager() dic = manage.dict() for i in range(10): p = Process(target=Foo, args=(i,dic)) p.start() p.join() Manager比Array要好用一点，因为它可以同时保存多种类型的数据格式。 2.1.3 使用queues的Queue类共享数据 import multiprocessing from multiprocessing import Process from multiprocessing import queues def foo(i,arg): arg.put(i) print(&apos;The Process is &apos;, i, &quot;and the queue&apos;s size is &quot;, arg.qsize()) if __name__ == &quot;__main__&quot;: li = queues.Queue(20, ctx=multiprocessing) for i in range(10): p = Process(target=foo, args=(i,li,)) p.start() 这里就有点类似上面的队列了。从运行结果里，你还能发现数据共享中存在的脏数据问题。另外，比较悲催的是multiprocessing里还有一个Queue，一样能实现这个功能。 2.2 进程锁 为了防止和多线程一样的出现数据抢夺和脏数据的问题，同样需要设置进程锁。与threading类似，在multiprocessing里也有同名的锁类RLock, Lock, Event, Condition, Semaphore，连用法都是一样样的！（这个我喜欢） from multiprocessing import Process from multiprocessing import queues from multiprocessing import Array from multiprocessing import RLock, Lock, Event, Condition, Semaphore import multiprocessing import time def foo(i,lis,lc): lc.acquire() lis[0] = lis[0] - 1 time.sleep(1) print(&apos;say hi&apos;,lis[0]) lc.release() if __name__ == &quot;__main__&quot;: # li = [] li = Array(&apos;i&apos;, 1) li[0] = 10 lock = RLock() for i in range(10): p = Process(target=foo,args=(i,li,lock)) p.start() 2.3 进程池 既然有线程池，那必然也有进程池。但是，python给我们内置了一个进程池，不需要像线程池那样需要自定义，你只需要简单的from multiprocessing import Pool。 #!/usr/bin/env python # -*- coding:utf-8 -*- from multiprocessing import Pool import time def f1(args): time.sleep(1) print(args) if __name__ == &apos;__main__&apos;: p = Pool(5) for i in range(30): p.apply_async(func=f1, args= (i,)) p.close() # 等子进程执行完毕后关闭进程池 # time.sleep(2) # p.terminate() # 立刻关闭进程池 p.join() 进程池内部维护一个进程序列，当使用时，去进程池中获取一个进程，如果进程池序列中没有可供使用的进程，那么程序就会等待，直到进程池中有可用进程为止。进程池中有以下几个主要方法： apply：从进程池里取一个进程并执行 apply_async：apply的异步版本 terminate:立刻关闭进程池 join：主进程等待所有子进程执行完毕。必须在close或terminate之后。 close：等待所有进程结束后，才关闭进程池。 三、协程 线程和进程的操作是由程序触发系统接口，最后的执行者是系统，它本质上是操作系统提供的功能。而协程的操作则是程序员指定的，在python中通过yield，人为的实现并发处理。 协程存在的意义：对于多线程应用，CPU通过切片的方式来切换线程间的执行，线程切换时需要耗时。协程，则只使用一个线程，分解一个线程成为多个“微线程”，在一个线程中规定某个代码块的执行顺序。 协程的适用场景：当程序中存在大量不需要CPU的操作时（IO）。 在不需要自己“造轮子”的年代，同样有第三方模块为我们提供了高效的协程，这里介绍一下greenlet和gevent。本质上，gevent是对greenlet的高级封装，因此一般用它就行，这是一个相当高效的模块。 在使用它们之前，需要先安装，可以通过源码，也可以通过pip。 3.1 greenlet from greenlet import greenlet def test1(): print(12) gr2.switch() print(34) gr2.switch() def test2(): print(56) gr1.switch() print(78) gr1 = greenlet(test1) gr2 = greenlet(test2) gr1.switch() 实际上，greenlet就是通过switch方法在不同的任务之间进行切换。 3.2 gevent from gevent import monkey; monkey.patch_all() import gevent import requests def f(url): print(&apos;GET: %s&apos; % url) resp = requests.get(url) data = resp.text print(&apos;%d bytes received from %s.&apos; % (len(data), url)) gevent.joinall([ gevent.spawn(f, &apos;https://www.python.org/&apos;), gevent.spawn(f, &apos;https://www.yahoo.com/&apos;), gevent.spawn(f, &apos;https://github.com/&apos;), ]) 通过joinall将任务f和它的参数进行统一调度，实现单线程中的协程。代码封装层次很高，实际使用只需要了解它的几个主要方法即可。","categories":[{"name":"python","slug":"python","permalink":"http://yoursite.com/categories/python/"}],"tags":[{"name":"进程 线程","slug":"进程-线程","permalink":"http://yoursite.com/tags/进程-线程/"}]},{"title":"python之==和is","slug":"等号和is","date":"2017-03-29T16:00:00.000Z","updated":"2018-03-06T12:57:46.356Z","comments":true,"path":"2017/03/30/等号和is/","link":"","permalink":"http://yoursite.com/2017/03/30/等号和is/","excerpt":"","text":"关于 == 和 is 判断内容的时候使用== #这里比较的是两个对象中的值，而不进行内存地址的检测，返回布尔值 &gt;&gt;&gt;a = [1,2,3] &gt;&gt;&gt;b = [1,2,3] &gt;&gt;&gt;a == b True 判断是否指向同一个对象的时候用is &gt;&gt;&gt;a = [1,2,3] &gt;&gt;&gt;b = [1,2,3] &gt;&gt;&gt; id(a) 45600072 &gt;&gt;&gt; id(b) 45721032 &gt;&gt;&gt; a is b False 这里需要注意的是： 1,整数在程序中的使用非常广泛，Python为了优化速度，使用了小整数对象池，避免为整数频繁申请和销毁内存空间。python对小整数的定义是[-5,257],也就是-5到256且包含256，这些整数对象是提前建立好的，在一个python的程序中，所有位于这个范围内的整数使用的都是同一个对象。同理，单个字母也是这样的。2,如果定义的变量都是普通字母，不包含其他特殊符号的，默认开启intern机制，共用对象，不会进行新建例子： &gt;&gt;&gt; a = 100 &gt;&gt;&gt; b = 100 &gt;&gt;&gt; a is b True &gt;&gt;&gt; a = &apos;hehe&apos; &gt;&gt;&gt; b = &apos;hehe&apos; &gt;&gt;&gt; a is b True","categories":[{"name":"python","slug":"python","permalink":"http://yoursite.com/categories/python/"}],"tags":[{"name":"运算符","slug":"运算符","permalink":"http://yoursite.com/tags/运算符/"}]},{"title":"静态方法和类方法","slug":"静态方法和类方法","date":"2017-03-28T16:00:00.000Z","updated":"2018-03-06T12:57:39.738Z","comments":true,"path":"2017/03/29/静态方法和类方法/","link":"","permalink":"http://yoursite.com/2017/03/29/静态方法和类方法/","excerpt":"","text":"类方法是类对象所拥有的方法，需要用修饰器@classmethod来标识其为类方法，对于类方法，第一个参数必须是类对象，一般以cls作为第一个参数（当然可以用其他名称的变量作为其第一个参数，但是大部分人都习惯以’cls’作为第一个参数的名字，就最好用’cls’了），能够通过实例对象和类对象去访问。 class People(object): country = &apos;china&apos; #类方法，用classmethod来进行修饰 @classmethod def getCountry(cls): return cls.country p = People() print p.getCountry() #可以用过实例对象引用 print People.getCountry() #可以通过类对象引用 类方法还有一个用途就是可以对类属性进行修改： class People(object): country = &apos;china&apos; #类方法，用classmethod来进行修饰 @classmethod def getCountry(cls): return cls.country @classmethod def setCountry(cls,country): cls.country = country p = People() print p.getCountry() #可以用过实例对象引用 print People.getCountry() #可以通过类对象引用 p.setCountry(&apos;japan&apos;) print p.getCountry() print People.getCountry() #输出 &gt;&gt;&gt;china &gt;&gt;&gt;china &gt;&gt;&gt;japan &gt;&gt;&gt;japan 结果显示在用类方法对类属性修改之后，通过类对象和实例对象访问都发生了改变 静态方法需要通过修饰器@staticmethod来进行修饰，静态方法不需要多定义参数 class People(object): country = &apos;china&apos; @staticmethod #静态方法 def getCountry(): return People.country print People.getCountry() 总结 从类方法和实例方法以及静态方法的定义形式就可以看出来，类方法的第一个参数是类对象cls，那么通过cls引用的必定是类对象的属性和方法；而实例方法的第一个参数是实例对象self，那么通过self引用的可能是类属性、也有可能是实例属性（这个需要具体分析），不过在存在相同名称的类属性和实例属性的情况下，实例属性优先级更高。静态方法中不需要额外定义参数，因此在静态方法中引用类属性的话，必须通过类对象来引用","categories":[{"name":"python","slug":"python","permalink":"http://yoursite.com/categories/python/"}],"tags":[{"name":"静态方法和类方法","slug":"静态方法和类方法","permalink":"http://yoursite.com/tags/静态方法和类方法/"}]},{"title":"单元测试","slug":"单元测试","date":"2017-03-27T16:00:00.000Z","updated":"2018-03-06T12:57:33.997Z","comments":true,"path":"2017/03/28/单元测试/","link":"","permalink":"http://yoursite.com/2017/03/28/单元测试/","excerpt":"","text":"转载自廖雪峰官网 如果你听说过“测试驱动开发”（TDD：Test-Driven Development），单元测试就不陌生。 单元测试是用来对一个模块、一个函数或者一个类来进行正确性检验的测试工作。 比如对函数abs()，我们可以编写出以下几个测试用例： 输入正数，比如1、1.2、0.99，期待返回值与输入相同； 输入负数，比如-1、-1.2、-0.99，期待返回值与输入相反； 输入0，期待返回0； 输入非数值类型，比如None、[]、{}，期待抛出TypeError。 把上面的测试用例放到一个测试模块里，就是一个完整的单元测试。 如果单元测试通过，说明我们测试的这个函数能够正常工作。如果单元测试不通过，要么函数有bug，要么测试条件输入不正确，总之，需要修复使单元测试能够通过。 单元测试通过后有什么意义呢？如果我们对abs()函数代码做了修改，只需要再跑一遍单元测试，如果通过，说明我们的修改不会对abs()函数原有的行为造成影响，如果测试不通过，说明我们的修改与原有行为不一致，要么修改代码，要么修改测试。 这种以测试为驱动的开发模式最大的好处就是确保一个程序模块的行为符合我们设计的测试用例。在将来修改的时候，可以极大程度地保证该模块行为仍然是正确的。 我们来编写一个Dict类，这个类的行为和dict一致，但是可以通过属性来访问，用起来就像下面这样： &gt;&gt;&gt; d = Dict(a=1, b=2) &gt;&gt;&gt; d[&apos;a&apos;] 1 &gt;&gt;&gt; d.a 1 mydict.py代码如下： class Dict(dict): def __init__(self, **kw): super().__init__(**kw) def __getattr__(self, key): try: return self[key] except KeyError: raise AttributeError(r&quot;&apos;Dict&apos; object has no attribute &apos;%s&apos;&quot; % key) def __setattr__(self, key, value): self[key] = value 为了编写单元测试，我们需要引入Python自带的unittest模块，编写mydict_test.py如下： import unittest from mydict import Dict class TestDict(unittest.TestCase): def test_init(self): d = Dict(a=1, b=&apos;test&apos;) self.assertEqual(d.a, 1) self.assertEqual(d.b, &apos;test&apos;) self.assertTrue(isinstance(d, dict)) def test_key(self): d = Dict() d[&apos;key&apos;] = &apos;value&apos; self.assertEqual(d.key, &apos;value&apos;) def test_attr(self): d = Dict() d.key = &apos;value&apos; self.assertTrue(&apos;key&apos; in d) self.assertEqual(d[&apos;key&apos;], &apos;value&apos;) def test_keyerror(self): d = Dict() with self.assertRaises(KeyError): value = d[&apos;empty&apos;] def test_attrerror(self): d = Dict() with self.assertRaises(AttributeError): value = d.empty 编写单元测试时，我们需要编写一个测试类，从unittest.TestCase继承。 以test开头的方法就是测试方法，不以test开头的方法不被认为是测试方法，测试的时候不会被执行。 对每一类测试都需要编写一个test_xxx()方法。由于unittest.TestCase提供了很多内置的条件判断，我们只需要调用这些方法就可以断言输出是否是我们所期望的。最常用的断言就是assertEqual()： self.assertEqual(abs(-1), 1) # 断言函数返回的结果与1相等 另一种重要的断言就是期待抛出指定类型的Error，比如通过d[‘empty’]访问不存在的key时，断言会抛出KeyError： with self.assertRaises(KeyError): value = d[&apos;empty&apos;] 而通过d.empty访问不存在的key时，我们期待抛出AttributeError： with self.assertRaises(AttributeError): value = d.empty 运行单元测试一旦编写好单元测试，我们就可以运行单元测试。最简单的运行方式是在mydict_test.py的最后加上两行代码： if __name__ == &apos;__main__&apos;: unittest.main() 这样就可以把mydict_test.py当做正常的python脚本运行： $ python mydict_test.py 另一种方法是在命令行通过参数-m unittest直接运行单元测试： $ python -m unittest mydict_test ..... ---------------------------------------------------------------------- Ran 5 tests in 0.000s OK 这是推荐的做法，因为这样可以一次批量运行很多单元测试，并且，有很多工具可以自动来运行这些单元测试。 setUp与tearDown可以在单元测试中编写两个特殊的setUp()和tearDown()方法。这两个方法会分别在每调用一个测试方法的前后分别被执行。 setUp()和tearDown()方法有什么用呢？设想你的测试需要启动一个数据库，这时，就可以在setUp()方法中连接数据库，在tearDown()方法中关闭数据库，这样，不必在每个测试方法中重复相同的代码： class TestDict(unittest.TestCase): def setUp(self): print(&apos;setUp...&apos;) def tearDown(self): print(&apos;tearDown...&apos;) 可以再次运行测试看看每个测试方法调用前后是否会打印出setUp…和tearDown…。","categories":[{"name":"python","slug":"python","permalink":"http://yoursite.com/categories/python/"}],"tags":[{"name":"单元测试","slug":"单元测试","permalink":"http://yoursite.com/tags/单元测试/"}]},{"title":"python之property","slug":"property","date":"2017-03-26T16:00:00.000Z","updated":"2018-03-06T12:57:30.047Z","comments":true,"path":"2017/03/27/property/","link":"","permalink":"http://yoursite.com/2017/03/27/property/","excerpt":"","text":"在工作中，在绑定属性的时候，如果我们直接把属性写成全局的，虽然写起来比较简单，但是容易被随便修改，不符合逻辑，这时就需要把该属性进行限制，改成私有属性，通过内部方法进行调用或者修改以及检测 例子： class Test(object): def __init__(self): self.__num = 100 def getNum(self): return self.__num def setNum(self,newNum): if not isinstance(newNum, int): raise ValueError(&apos;该值必须是一个整数！&apos;) if newNum &lt; 0 or newNum &gt; 300: raise ValueError(&apos;该值必须在0 ~ 300!&apos;) self.__num = newNum t = Test() t.getNum()#获取该值 t.setNum(300)#设置该值 上面这种方式有点繁琐，python还有更好的方式，通过属性的方式 class Test(object): def __init__(self): self.__num = 100 def getNum(self): return self.__num def setNum(self,newNum): if not isinstance(newNum, int): raise ValueError(&apos;该值必须是一个整数！&apos;) if newNum &lt; 0 or newNum &gt; 300: raise ValueError(&apos;该值必须在0 ~ 300!&apos;) self.__num = newNum #只需要在这里进行改写 #这里python会自动检测是设置或是获取，如果获取，则执行getNum，如果是设置，则执行setNum，相当于对该方法进行了简单的封装 #这里需要注意的是：获取一定要放在前面，顺序混淆会报错 num = property(getNum,setNum) t = Test() #可以通过这两个方法进行设置和获取以及设置的时候进行验证 #这是只要通过获取或者设置属性的方式就可以实现和上面一样的功能 t.num #等价于上面的t.getNum() t.num = 300 #等价于上面的t.getNum(300) 在这里再介绍一种property的使用方式,通过装饰器的方法进行实现 class Test(object): def __init__(self): self.__num = 100 #通过装饰器的方式进行实现 #这里等价于上面的，getNum()方法 @property def num(self): return self.__num #这里等价于上面的setNum()方法 @num.setter def num(self,newNum): if not isinstance(newNum, int): raise ValueError(&apos;该值必须是一个整数！&apos;) if newNum &lt; 0 or newNum &gt; 300: raise ValueError(&apos;该值必须在0 ~ 300!&apos;) self.__num = newNum 注意到这个神奇的@property，我们在对实例属性操作的时候，就知道该属性很可能不是直接暴露的，而是通过getter和setter方法来实现的。 还可以定义只读属性，只定义getter方法，不定义setter方法就是一个只读属性： class Test(object): def __init__(self): self.__num = 100 @property def num(self): return self.__num @num.setter def num(self,newNum): if not isinstance(newNum, int): raise ValueError(&apos;该值必须是一个整数！&apos;) if newNum &lt; 0 or newNum &gt; 300: raise ValueError(&apos;该值必须在0 ~ 300!&apos;) self.__num = newNum @prorerty def oldNum(self): return 999-self.__num 上面的num是可读写属性，而oldNum就是一个只读属性。 总结：Python内置的@property装饰器就是负责把一个方法变成属性调用的：@property的实现比较复杂，我们先考察如何使用。把一个getter方法变成属性，只需要加上@property就可以了，此时，@property本身又创建了另一个装饰器@num.setter，负责把一个setter方法变成属性赋值，于是，我们就拥有一个可控的属性操作。 @property广泛应用在类的定义中，可以让调用者写出简短的代码，同时保证对参数进行必要的检查，这样，程序运行时就减少了出错的可能性。","categories":[{"name":"python","slug":"python","permalink":"http://yoursite.com/categories/python/"}],"tags":[{"name":"property","slug":"property","permalink":"http://yoursite.com/tags/property/"}]},{"title":"python之装饰器","slug":"装饰器","date":"2017-03-23T16:00:00.000Z","updated":"2018-03-06T12:56:49.285Z","comments":true,"path":"2017/03/24/装饰器/","link":"","permalink":"http://yoursite.com/2017/03/24/装饰器/","excerpt":"","text":"装饰器的作用在原来代码的基础上进行功能扩展 例如：原来我们有2个方法，f1和f2 def f1(): print(&apos;f1&apos;) def f2(): print(&apos;f2&apos;) f1() f2() 现在我们需要给这两个方法调用前加一个验证，验证成功就调用，失败则不调用：首先我们使用一种普通方法： def w1(func): def inner(): print(‘正在验证中’) if True: func() else: print(‘验证失败，请重试’) return inner def f1(): print(&apos;f1&apos;) def f2(): print(&apos;f2&apos;) x = w1(f1) x() y = w1(f2) y() 这种方式基本实现了所需要的验证功能 接下来我们使用通过用装饰器实现的写法： def w1(func): def inner(): print(‘正在验证’) if True: func() else: print(‘验证失败，请重试’) return inner @w1 #相当于w1(f1) def f1(): print(&apos;f1&apos;) @w1 #相当于w1(f2) def f2(): print(&apos;f2&apos;) f1() f2() 类装饰器 class Test(object): def __init__(self,fn): print(&apos;初始化&apos;) print(&apos;fn的名字是{0}&apos;.format(fn.__name__)) self.__fn = fn def __call__(self): print(&apos;---装饰器中的功能---&apos;) self.__fn() @Test #这里的这一步就相当于 # test = Test(test) #也就是实例化一个对象，实例化的时候会触发__init__函数执行，现在 #test也就等于了一个已经实例化后的对象 #如果这里在调用test(),就会触发类里的__call__方法 def test(): print(&apos;====test====&apos;) test() &gt;&gt;&gt;初始化 &gt;&gt;&gt;fn的名字是test &gt;&gt;&gt;---装饰器中的功能--- &gt;&gt;&gt;====test====","categories":[{"name":"python","slug":"python","permalink":"http://yoursite.com/categories/python/"}],"tags":[{"name":"装饰器","slug":"装饰器","permalink":"http://yoursite.com/tags/装饰器/"}]},{"title":"深入python之浅拷贝和深拷贝","slug":"深拷贝和浅拷贝","date":"2017-03-22T16:00:00.000Z","updated":"2018-03-06T12:56:44.983Z","comments":true,"path":"2017/03/23/深拷贝和浅拷贝/","link":"","permalink":"http://yoursite.com/2017/03/23/深拷贝和浅拷贝/","excerpt":"","text":"关于python中的浅拷贝和深拷贝在Python中，首先要讲的就是等号赋值了，其实这种拷贝只是给源对象新增一个标签而已，指向的还是同一个对象： 例：&gt;&gt;&gt;a = [1,2,3] &gt;&gt;&gt;b = a #打印a的内存地址 &gt;&gt;&gt;id(a) 45817096 #打印b的内存地址 &gt;&gt;&gt;id(b) 45817096 #这里的a和b指向的是同一个对象 接下来就是我们要讲的浅拷贝和深拷贝，实现深浅拷贝首先需要引入copy模块: 1：浅拷贝,使用copy模块下的copy()方法实现： &gt;&gt;&gt;import copy &gt;&gt;&gt;a = [1,2,3,4] &gt;&gt;&gt;b = copy.copy(a) &gt;&gt;&gt; id(a) 47818184 &gt;&gt;&gt; id(b) 47856904 # 在这里我们发现b和a的内存地址不同，相当于复制一份新的列表[1,2,3,4]给了b,如果现在修改a的值，b的值不会随之变化： &gt;&gt;&gt; a.append(10) &gt;&gt;&gt; a [1, 2, 3, 4, 10] &gt;&gt;&gt; b [1, 2, 3, 4] # 我们接着往下走： &gt;&gt;&gt; aa = [1,2,3,[&apos;a&apos;,&apos;b&apos;]] &gt;&gt;&gt; bb = copy.copy(aa) &gt;&gt;&gt; id(aa) 47914120 &gt;&gt;&gt; id(bb) 47697096 # 接着我们继续输出列表嵌套内的列表的内存地址 &gt;&gt;&gt; id(aa[3]) 47696776 &gt;&gt;&gt; id(bb[3]) 47696776 # 在这里我们发现内部嵌套的列表的内存地址是相同的，这里就说明了浅拷贝仅仅只是拷贝了父对象，而不会拷贝扶对象内部的子对象 2：深拷贝，使用copy模块下的deepcopy()方法实现： &gt;&gt;&gt;import copy &gt;&gt;&gt;a = [1,2,3,4] &gt;&gt;&gt;b = copy.deepcopy(a) &gt;&gt;&gt; id(a) 47818184 &gt;&gt;&gt; id(b) 47856904 #这里可以看到，如果当前拷贝对象没有子对象的时候，copy()和deep()没有区别 #接着往下看： &gt;&gt;&gt; a = [1,2,3,4,[&apos;x&apos;,&apos;y&apos;]] &gt;&gt;&gt; b = copy.deepcopy() &gt;&gt;&gt; id(a[4]) 47733896 &gt;&gt;&gt; id(b[4]) 47914056 #这里我们发现，深拷贝会拷贝当前对象及其子对象，不论父对象嵌套多少子对象都会进行完全拷贝 我们发现，刚才举例的时候只是用到了列表，实际工作中用到的不止有列表这么一种数据类型，我们不妨试一下其他的类型，比如试一试元祖： &gt;&gt;&gt; a = (1,2,3,4,[&apos;aa&apos;,&apos;bb&apos;]) &gt;&gt;&gt; b = copy.copy(a) &gt;&gt;&gt; id(a) 45195112 &gt;&gt;&gt; id(b) 45195112 &gt;&gt;&gt; id(a[4]) 46124808 &gt;&gt;&gt; id(b[4]) 46124808 #这里我们发现浅拷贝元祖的时候父对象也没有实现拷贝，还是指向了原来对象的内存地址 &gt;&gt;&gt; c = copy.deepcopy(a) &gt;&gt;&gt; id(c) 45853160 &gt;&gt;&gt; id(c[4]) 46169224 &gt;&gt;&gt; id(a[4]) 46124808 #而深拷贝还是一如既往的一致，父对象和子对象都进行了拷贝 #其实这里python默认帮我们进行了类型检测，如果是不可变类型则无法进行浅拷贝，只可以执行深拷贝，这个需要重点记忆，工作中可能就莫名出现此类BUG； 小结： copy.copy() 浅拷贝 只拷贝父对象，不会拷贝对象的内部的子对象。 copy.deepcopy() 深拷贝 拷贝对象及其子对象 如果拷贝的类型是不可变类型的时候，浅拷贝不会拷贝父对象，只有深拷贝会执行拷贝","categories":[{"name":"python","slug":"python","permalink":"http://yoursite.com/categories/python/"}],"tags":[{"name":"模块 copy","slug":"模块-copy","permalink":"http://yoursite.com/tags/模块-copy/"}]},{"title":"python之内建函数","slug":"内建函数","date":"2017-03-21T16:00:00.000Z","updated":"2018-03-06T12:56:40.096Z","comments":true,"path":"2017/03/22/内建函数/","link":"","permalink":"http://yoursite.com/2017/03/22/内建函数/","excerpt":"","text":"1，map函数 定义：map函数会根据提供的函数对指定序列做映射，生成新的列表 map(function,sequence[,sequence,…]) &gt;&gt;list function是一个函数sequence是一个或者多个学列，取决于function需要几个参数python3中返回的是map对象，需要迭代才能获取对象中的值，可以在外面转换成list对象 参数学列中的每一个元素分别调用function函数，返回包含每次function函数返回的map对象 例1： &gt;&gt;&gt; k = map(lambda x:x*x, [1,2,3]) &gt;&gt;&gt; k &gt;&gt;&gt; for i in k: print(i) 1 4 9 &gt;&gt;&gt; k =list(map(lambda x:x*x, [1,2,3])) &gt;&gt;&gt; k 1 4 9 例2： #函数需要2个参数的情况 &gt;&gt;&gt; m = list(map(lambda x,y:x+y,[1,2,3],[4,5,6])) &gt;&gt;&gt; m [5, 7, 9] 例3：上面两个例子都是用匿名函数的方式，下面来看不使用匿名函数的方式： &gt;&gt;&gt; def f1(x,y): return (x,y) &gt;&gt;&gt; a1 = [1,2,3,4,5,6] &gt;&gt;&gt; a2 = [&apos;a&apos;,&apos;b&apos;,&apos;c&apos;,&apos;d&apos;,&apos;e&apos;,&apos;f&apos;] &gt;&gt;&gt; list(map(f1,a1,a2)) [(1, &apos;a&apos;), (2, &apos;b&apos;), (3, &apos;c&apos;), (4, &apos;d&apos;), (5, &apos;e&apos;), (6, &apos;f&apos;)] 2，filter 定义：filter函数会对制定序列执行过滤、筛选操作 filter(function or None,squence)&gt;&gt;&gt;list,tuple,or string function:接受一个参数，返回布尔值True或False sequence:序列可以是str,tuple,list filter函数会对序列参数sequence中的每个元素调用function函数，最后返回的结果包含调用结果为True的元素。返回值的类型和参数sequence的类型相同 例1： &gt;&gt;&gt; list(filter(lambda x:x%2,[1,2,3,4,5,6,7,8])) [1, 3, 5, 7] 3，sorted函数 定义：对参数进行排序返回新的列表，如果是字母则通过ASII码进行排序 例1：正序排序 &gt;&gt;&gt; sorted([1,2,3,5,3,12,4,1234,34,343]) [1, 2, 3, 3, 4, 5, 12, 34, 343, 1234] 例2：倒序排序 &gt;&gt;&gt; sorted([4,66,1,65,23,8,5,],reverse = True) [66, 65, 23, 8, 5, 4, 1] 例3：字母排序 &gt;&gt;&gt; sorted([&apos;a&apos;,&apos;c&apos;,&apos;e&apos;,&apos;b&apos;,&apos;f&apos;]) [&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;e&apos;, &apos;f&apos;] #如果是单词的话会通过它们首字母的asii码进行排序 &gt;&gt;&gt; sorted([&apos;hello&apos;,&apos;world&apos;,&apos;name&apos;,&apos;args&apos;]) [&apos;args&apos;, &apos;hello&apos;, &apos;name&apos;, &apos;world&apos;]","categories":[{"name":"python","slug":"python","permalink":"http://yoursite.com/categories/python/"}],"tags":[{"name":"内建函数","slug":"内建函数","permalink":"http://yoursite.com/tags/内建函数/"}]},{"title":"python之垃圾回收","slug":"垃圾回收","date":"2017-03-20T16:00:00.000Z","updated":"2018-03-06T12:56:37.104Z","comments":true,"path":"2017/03/21/垃圾回收/","link":"","permalink":"http://yoursite.com/2017/03/21/垃圾回收/","excerpt":"","text":"垃圾回收机制（GC） 关于垃圾回收高级语言里都采用了垃圾回收机制，而不再是C，C++里用户自己管理内存。在python里采用的是引用技术机制为主，标记-清除和分代手机两种机制为辅的策略 关于引用计数python里每个东西都是对象，通过底层的一个方法对当前对象的引用进行计数,当一个对象有新的引用的时候，它的计数就会增加，当引用它的对象被删除，它的引用计数就减少，当引用计数为0的时候，该对象生命就结束了。 优点：1，简单2，实时性：一旦没有引用，内存就直接释放了。不用想其他机制等待特定时机，实时性带来的另外一个好处，处理回收内存的时间分摊了，不会等到特定时间做特定的事情。 缺点：1，维护引用计数消耗资源2，循环引用的问题，已经通过隔代回收的方式进行了处理，首先创建对象之后在特定时间会进行检测2个对象之间是否在进行相互引用，如果是则进行回收。然后把没被清除的对象移动到下个数据链中。然后继续进行在特定时间进行检测。 更底层的进行垃圾回收管理需要引入gc模块进行管理，这里就不进行深入理解了。","categories":[{"name":"python","slug":"python","permalink":"http://yoursite.com/categories/python/"}],"tags":[{"name":"垃圾回收","slug":"垃圾回收","permalink":"http://yoursite.com/tags/垃圾回收/"}]},{"title":"python之进程的创建","slug":"进程的创建fork","date":"2017-03-19T16:00:00.000Z","updated":"2018-03-06T12:56:32.547Z","comments":true,"path":"2017/03/20/进程的创建fork/","link":"","permalink":"http://yoursite.com/2017/03/20/进程的创建fork/","excerpt":"","text":"1，进程和程序 编写完毕的代码，在没有运行的时候，称之为程序正在运行着的代码，就成为进程进程，除了包含代码以外，还有需要运行的环境等，所以和程序是有区别的 2，fork()","categories":[{"name":"python","slug":"python","permalink":"http://yoursite.com/categories/python/"}],"tags":[{"name":"进程","slug":"进程","permalink":"http://yoursite.com/tags/进程/"}]},{"title":"python之集合","slug":"集合","date":"2017-03-16T16:00:00.000Z","updated":"2018-03-01T14:03:21.079Z","comments":true,"path":"2017/03/17/集合/","link":"","permalink":"http://yoursite.com/2017/03/17/集合/","excerpt":"","text":"定义：python的set和其他语言类似, 是一个无序不重复元素集, 基本功能包括关系测试和消除重复元素. 集合对象还支持union(联合), intersection(交), difference(差)和sysmmetric difference(对称差集)等数学运算. sets 支持 x in set, len(set),和 for x in set。作为一个无序的集合，sets不记录元素位置或者插入点。因此，sets不支持 indexing, slicing, 或其它类序列（sequence-like）的操作。 1，集合功能之一：列表去重因为集合是无序不重复元素集，利用这一特性可以进行列表的去重操作例： &gt;&gt;&gt; a = [11,23,345,657,453,123,11,23,345,657,453,123] &gt;&gt;&gt; b = set(a) &gt;&gt;&gt; b {453, 11, 657, 23, 345, 123} &gt;&gt;&gt; a = list(b) &gt;&gt;&gt; a [453, 11, 657, 23, 345, 123] 2，集合功能之二：交集 &gt;&gt;&gt; a = {&apos;a&apos;,&apos;b&apos;,&apos;d&apos;,&apos;f&apos;,&apos;l&apos;,&apos;k&apos;,&apos;m&apos;} &gt;&gt;&gt; b = {&apos;k&apos;,&apos;s&apos;,&apos;q&apos;,&apos;k&apos;,&apos;y&apos;,&apos;z&apos;,&apos;b&apos;} &gt;&gt;&gt; a&amp;b {&apos;b&apos;, &apos;k&apos;} 3，集合功能之三：并集 &gt;&gt;&gt; a = {&apos;a&apos;,&apos;b&apos;,&apos;d&apos;,&apos;f&apos;,&apos;l&apos;,&apos;k&apos;,&apos;m&apos;} &gt;&gt;&gt; b = {&apos;k&apos;,&apos;s&apos;,&apos;q&apos;,&apos;k&apos;,&apos;y&apos;,&apos;z&apos;,&apos;b&apos;} &gt;&gt;&gt; a | b {&apos;s&apos;, &apos;k&apos;, &apos;q&apos;, &apos;m&apos;, &apos;z&apos;, &apos;l&apos;, &apos;f&apos;, &apos;a&apos;, &apos;d&apos;, &apos;y&apos;, &apos;b&apos;} 4，集合功能之四：差集 &gt;&gt;&gt; a = {&apos;a&apos;,&apos;b&apos;,&apos;d&apos;,&apos;f&apos;,&apos;l&apos;,&apos;k&apos;,&apos;m&apos;} &gt;&gt;&gt; b = {&apos;k&apos;,&apos;s&apos;,&apos;q&apos;,&apos;k&apos;,&apos;y&apos;,&apos;z&apos;,&apos;b&apos;} &gt;&gt;&gt; a-b #a中有的而b中没有的 {&apos;m&apos;, &apos;l&apos;, &apos;f&apos;, &apos;a&apos;, &apos;d&apos;} 5，集合功能之五：对称差集 &gt;&gt;&gt; a = {&apos;a&apos;,&apos;b&apos;,&apos;d&apos;,&apos;f&apos;,&apos;l&apos;,&apos;k&apos;,&apos;m&apos;} &gt;&gt;&gt; b = {&apos;k&apos;,&apos;s&apos;,&apos;q&apos;,&apos;k&apos;,&apos;y&apos;,&apos;z&apos;,&apos;b&apos;} &gt;&gt;&gt; a^b #a有的，b没有的，b有的，a没有的 {&apos;s&apos;, &apos;q&apos;, &apos;z&apos;, &apos;m&apos;, &apos;l&apos;, &apos;f&apos;, &apos;a&apos;, &apos;y&apos;, &apos;d&apos;}","categories":[{"name":"python","slug":"python","permalink":"http://yoursite.com/categories/python/"}],"tags":[{"name":"set集合","slug":"set集合","permalink":"http://yoursite.com/tags/set集合/"}]},{"title":"python之对象池","slug":"对象池","date":"2017-03-15T16:00:00.000Z","updated":"2018-03-01T14:00:27.140Z","comments":true,"path":"2017/03/16/对象池/","link":"","permalink":"http://yoursite.com/2017/03/16/对象池/","excerpt":"","text":"1、小整数对象池整数在程序中的使用非常广泛，Python为了优化速度，使用了小整数对象池，避免为整数频繁申请和销毁内存空间。python对小整数的定义是[-5,257],也就是-5到256且包含256，这些整数对象是提前建立好的，不会被垃圾回收，在一个python的程序中，所有位于这个范围内的整数使用的都是同一个对象。同理，单个字母也是这样的。但是当定义2个相同的字符串的时候，引用计数为0，触发垃圾回收 2、大整数对象池（什么时候使用，什么时候创建，小整数池之外的整数）每一个大整数，均创建一个新的对象 3、intern机制 如果定义的变量都是普通字母，不包含其他特殊符号的，默认开启intern机制，共用对象，不会进行新建 总结： 小整数[-5,257]共用对象，常驻内存 单个字符共用对象，常驻内存 单个单词，不可修改，默认开启intern机制，共用对象，引用计数为0，则销毁 字符串（含有空格），不可修改，不开启intern机制，不共用对象，引用计数为0，则销毁","categories":[{"name":"python","slug":"python","permalink":"http://yoursite.com/categories/python/"}],"tags":[{"name":"对象池","slug":"对象池","permalink":"http://yoursite.com/tags/对象池/"}]},{"title":"python之动态添加属性方法","slug":"动态添加属性和方法","date":"2017-03-14T16:00:00.000Z","updated":"2018-03-01T13:58:18.517Z","comments":true,"path":"2017/03/15/动态添加属性和方法/","link":"","permalink":"http://yoursite.com/2017/03/15/动态添加属性和方法/","excerpt":"","text":"工作中，我们需要给某一个实例对象新添加一个新的实例方法，如果用添加属性的方法进行添加的话直接会报错： class Person: def __init__(self,newName,newAge): self.name = newName self.age = newAge def eat(self): print(&apos;==={0}正在吃&apos;.format(self.name)) p1 = Person(&apos;p1&apos;,20) p1.eat() def run(self): print(&apos;===={0}正在跑&apos;.format(self.name)) p1.run = run #虽然p1对象中run属性指向了run函数，但是因为run属性指向的函数是后来添加的，调用的时候并没有把p1这个属性传进去，所以会报参数错误 其实python提供了一个方法供我们动态的给对象添加一个方法： 这时候我们可以通过一个types模块里的方法实现动态添加方法 import types 这里的第一个参数是要添加的方法，第二个参数是要添加的对象然后把它赋给要绑定的这个对象的方法 p1.run = types.MethodType(run,p1) 这时候就可以直接调用新添加的方法了 p1.run() 注意：只有实例对象动态添加一个方法的时候需要types.MethodType方法而给类添加静态方法和类方法则不需要这种写法 #添加类方法 @classmethod def printNum(cls): print(&apos;classMethod&apos;) P1.printNum = printNum P1.printNum() #添加静态方法 @staticmethod def test(): print(&apos;静态方法&apos;) P1.test = test P1.test() 如果我们想要显示实例的属性怎么办呢？比如我们只允许是实例对象添加name和age属性，为了达到限定的目的，python允许在定义class的时候定义一个特殊的slots变量，来限制该class实例对象可以添加的属性： 注：这个变量的值必须放在一个元祖中 class Per(object): __slots__ = (&apos;name&apos;,&apos;age&apos;) #用tuple定义允许绑定的属性名称 p = Per() p.name = &apos;呵呵&apos; p.age = 111 print(p.name) print(p.age) p.add = &apos;北京&apos;#这里就会报错，找不到p.add这个属性 print(p.add)","categories":[{"name":"python","slug":"python","permalink":"http://yoursite.com/categories/python/"}],"tags":[{"name":"动态添加属性","slug":"动态添加属性","permalink":"http://yoursite.com/tags/动态添加属性/"}]},{"title":"python迭代、列表生成式和生成器","slug":"迭代、列表生成式和生成器","date":"2017-03-13T16:00:00.000Z","updated":"2018-03-01T13:46:00.141Z","comments":true,"path":"2017/03/14/迭代、列表生成式和生成器/","link":"","permalink":"http://yoursite.com/2017/03/14/迭代、列表生成式和生成器/","excerpt":"","text":"转载自廖雪峰官网：1,迭代 如果给定一个list或tuple等可迭代对象，我们可以通过for循环来遍历这些可迭代对象，这种遍历我们称为迭代 在python中，迭代是通过for in来完成的。 list这种数据类型虽然有下标，但很多其他数据类型是没有下标的，但是，只要是可迭代对象，无论有无下标，都可以迭代，比如dict就可以迭代： dicts = {&apos;a&apos;:1,&apos;b&apos;:2,&apos;c&apos;:3} #这里我们迭代的是字典的键 for key in dicts: print(key) #如果要迭代字典的值，可以用： for val in dicts.values(): print(val) 或者： for key in dicts: print(dicts[key]) #如果要同时获取键和值，则可以： for key,val in dicts.items(): print(key,val) 或者： for key in dicts: print(key,dicts[key]) 所以，当我们使用for循环时，只要作用于一个可迭代对象，for循环就可以正常运行，而我们不太关心该对象究竟是list还是其他数据类型。 那么，如何判断一个对象是可迭代对象呢？方法是通过collections模块的Iterable类型判断： &gt;&gt;&gt; from collections import Iterable &gt;&gt;&gt; isinstance(&apos;abc&apos;, Iterable) # str是否可迭代 True &gt;&gt;&gt; isinstance([1,2,3], Iterable) # list是否可迭代 True &gt;&gt;&gt; isinstance(123, Iterable) # 整数是否可迭代 False 最后一个小问题，如果要对list实现类似下标循环怎么办？Python内置的enumerate函数可以把一个list变成索引-元素对，这样就可以在for循环中同时迭代索引和元素本身： &gt;&gt;&gt; for i, value in enumerate([&apos;A&apos;, &apos;B&apos;, &apos;C&apos;]): ... print(i, value) ... 0 A 1 B 2 C &gt;&gt;&gt; for x, y in [(1, 1), (2, 4), (3, 9)]: ... print(x, y) ... 1 1 2 4 3 9 小结： 任何可迭代对象都可以作用于for循环，包括我们自定义的数据类型，只要符合迭代条件，就可以使用for循环。 2，列表生成式： 列表生成式即List Comprehensions，是Python内置的非常简单却强大的可以用来创建list的生成式。 举个例子，要生成list [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]可以用list(range(1, 11))： &gt;&gt;&gt; list(range(1, 11)) [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] 但如果要生成[1x1, 2x2, 3x3, …, 10x10]怎么做？方法一是循环： &gt;&gt;&gt; L = [] &gt;&gt;&gt; for x in range(1, 11): ... L.append(x * x) ... &gt;&gt;&gt; L [1, 4, 9, 16, 25, 36, 49, 64, 81, 100] 但是循环太繁琐，而列表生成式则可以用一行语句代替循环生成上面的list： &gt;&gt;&gt; [x * x for x in range(1, 11)] [1, 4, 9, 16, 25, 36, 49, 64, 81, 100] 写列表生成式时，把要生成的元素x * x放到前面，后面跟for循环，就可以把list创建出来，十分有用，多写几次，很快就可以熟悉这种语法。 for循环后面还可以加上if判断，这样我们就可以筛选出仅偶数的平方： &gt;&gt;&gt; [x * x for x in range(1, 11) if x % 2 == 0] [4, 16, 36, 64, 100]： 还可以使用两层循环，可以生成全排列： &gt;&gt;&gt; [m + n for m in &apos;ABC&apos; for n in &apos;XYZ&apos;] [&apos;AX&apos;, &apos;AY&apos;, &apos;AZ&apos;, &apos;BX&apos;, &apos;BY&apos;, &apos;BZ&apos;, &apos;CX&apos;, &apos;CY&apos;, &apos;CZ&apos;] 三层和三层以上的循环就很少用到了。 运用列表生成式，可以写出非常简洁的代码。例如，列出当前目录下的所有文件和目录名，可以通过一行代码实现： &gt;&gt;&gt; import os # 导入os模块，模块的概念后面讲到 &gt;&gt;&gt; [d for d in os.listdir(&apos;.&apos;)] # os.listdir可以列出文件和目录 [&apos;.emacs.d&apos;, &apos;.ssh&apos;, &apos;.Trash&apos;, &apos;Adlm&apos;, &apos;Applications&apos;, &apos;Desktop&apos;, &apos;Documents&apos;, &apos;Downloads&apos;, &apos;Library&apos;, &apos;Movies&apos;, &apos;Music&apos;, &apos;Pictures&apos;, &apos;Public&apos;, &apos;VirtualBox VMs&apos;, &apos;Workspace&apos;, &apos;XCode&apos;] for循环其实可以同时使用两个甚至多个变量，比如dict的items()可以同时迭代key和value： &gt;&gt;&gt; d = {&apos;x&apos;: &apos;A&apos;, &apos;y&apos;: &apos;B&apos;, &apos;z&apos;: &apos;C&apos; } &gt;&gt;&gt; for k, v in d.items(): ... print(k, &apos;=&apos;, v) ... y = B x = A z = C 因此，列表生成式也可以使用两个变量来生成list： &gt;&gt;&gt; d = {&apos;x&apos;: &apos;A&apos;, &apos;y&apos;: &apos;B&apos;, &apos;z&apos;: &apos;C&apos; } &gt;&gt;&gt; [k + &apos;=&apos; + v for k, v in d.items()] [&apos;y=B&apos;, &apos;x=A&apos;, &apos;z=C&apos;] 最后把一个list中所有的字符串变成小写： &gt;&gt;&gt; L = [&apos;Hello&apos;, &apos;World&apos;, &apos;IBM&apos;, &apos;Apple&apos;] &gt;&gt;&gt; [s.lower() for s in L] [&apos;hello&apos;, &apos;world&apos;, &apos;ibm&apos;, &apos;apple&apos;] 3,生成器 通过列表生成式，我们可以直接创建一个列表。但是，受到内存限制，列表容量肯定是有限的。而且，创建一个包含100万个元素的列表，不仅占用很大的存储空间，如果我们仅仅需要访问前面几个元素，那后面绝大多数元素占用的空间都白白浪费了。 所以，如果列表元素可以按照某种算法推算出来，那我们是否可以在循环的过程中不断推算出后续的元素呢？这样就不必创建完整的list，从而节省大量的空间。在Python中，这种一边循环一边计算的机制，称为生成器：generator。 要创建一个generator，有很多种方法。第一种方法很简单，只要把一个列表生成式的[]改成()，就创建了一个generator： &gt;&gt;&gt; L = [x * x for x in range(10)] &gt;&gt;&gt; L [0, 1, 4, 9, 16, 25, 36, 49, 64, 81] &gt;&gt;&gt; g = (x * x for x in range(10)) &gt;&gt;&gt; g &lt;generator object &lt;genexpr&gt; at 0x1022ef630&gt; 创建L和g的区别仅在于最外层的[]和()，L是一个list，而g是一个generator。 我们可以直接打印出list的每一个元素，但我们怎么打印出generator的每一个元素呢？ 如果要一个一个打印出来，可以通过next()函数获得generator的下一个返回值,也可以使用next方式来获取：例子：next(g) == g.next() &gt;&gt;&gt; next(g) 0 &gt;&gt;&gt; next(g) 1 &gt;&gt;&gt; next(g) 4 &gt;&gt;&gt; next(g) 9 &gt;&gt;&gt; next(g) 16 &gt;&gt;&gt; next(g) 25 &gt;&gt;&gt; next(g) 36 &gt;&gt;&gt; next(g) 49 &gt;&gt;&gt; next(g) 64 &gt;&gt;&gt; next(g) 81 &gt;&gt;&gt; next(g) Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt; StopIteration 所以，我们创建了一个generator后，基本上永远不会调用next()，而是通过for循环来迭代它，并且不需要关心StopIteration的错误。 generator非常强大。如果推算的算法比较复杂，用类似列表生成式的for循环无法实现的时候，还可以用函数来实现。 比如，著名的斐波拉契数列（Fibonacci），除第一个和第二个数外，任意一个数都可由前两个数相加得到： 1, 1, 2, 3, 5, 8, 13, 21, 34, … 斐波拉契数列用列表生成式写不出来，但是，用函数把它打印出来却很容易： def fib(max): n, a, b = 0, 0, 1 while n &lt; max: print(b) a, b = b, a + b n = n + 1 return ‘done’注意，赋值语句： a, b = b, a + b相当于： t = (b, a + b) # t是一个tuplea = t[0]b = t[1]但不必显式写出临时变量t就可以赋值。 上面的函数可以输出斐波那契数列的前N个数： fib(6)112358‘done’仔细观察，可以看出，fib函数实际上是定义了斐波拉契数列的推算规则，可以从第一个元素开始，推算出后续任意的元素，这种逻辑其实非常类似generator。 也就是说，上面的函数和generator仅一步之遥。要把fib函数变成generator，只需要把print(b)改为yield b就可以了： def fib(max): n, a, b = 0, 0, 1 while n &lt; max: yield b a, b = b, a + b n = n + 1 return ‘done’这就是定义generator的另一种方法。如果一个函数定义中包含yield关键字，那么这个函数就不再是一个普通函数，而是一个generator，也就是一个生成器： f = fib(6)f打印结果是一个生成器，而且用next()每次执行这个生成器的时候，会在遇到yield的时候进行终止，然后返回yield后面的值，等待下次的调用。 这里，最难理解的就是generator和函数的执行流程不一样。函数是顺序执行，遇到return语句或者最后一行函数语句就返回。而变成generator的函数，在每次调用next()的时候执行，遇到yield语句返回，再次执行时从上次返回的yield语句处继续执行。 举个简单的例子，定义一个generator，依次返回数字1，3，5： def odd(): print(‘step 1’) yield 1 print(‘step 2’) yield(3) print(‘step 3’) yield(5)调用该generator时，首先要生成一个generator对象，然后用next()函数不断获得下一个返回值： &gt;&gt;&gt; o = odd() &gt;&gt;&gt; next(o) step 1 1 &gt;&gt;&gt; next(o) step 2 3 &gt;&gt;&gt; next(o) step 3 5 &gt;&gt;&gt; next(o) Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt; StopIteration 可以看到，odd不是普通函数，而是generator，在执行过程中，遇到yield就中断，下次又继续执行。执行3次yield后，已经没有yield可以执行了，所以，第4次调用next(o)就报错。 回到fib的例子，我们在循环过程中不断调用yield，就会不断中断。当然要给循环设置一个条件来退出循环，不然就会产生一个无限数列出来。 同样的，把函数改成generator后，我们基本上从来不会用next()来获取下一个返回值，而是直接使用for循环来迭代： &gt;&gt;&gt; for n in fib(6): ... print(n) ... 1 1 2 3 5 8 但是用for循环调用generator时，发现拿不到generator的return语句的返回值。如果想要拿到返回值，必须捕获StopIteration错误，返回值包含在StopIteration的value中： &gt;&gt;&gt; g = fib(6) &gt;&gt;&gt; while True: ... try: ... x = next(g) ... print(&apos;g:&apos;, x) ... except StopIteration as e: ... print(&apos;Generator return value:&apos;, e.value) ... break ... g: 1 g: 1 g: 2 g: 3 g: 5 g: 8 Generator return value: done send方法的使用：从下面这个例子可以看出，send的方法使用起来和next功能差不多，只不过send方法会顺便给yield i这个整体一个返回值，剩下的功能就和next一样了注意：使用send（）传值的时候不能在第一次使用，这样会报错，如果第一次就要使用send,则给它传一个Nonesend(None) &gt;&gt;&gt; def test(): i = 0 while i&lt;5: temp = yield i print(temp) i+=1 &gt;&gt;&gt; test() &lt;generator object test at 0x0000000002DAA4C0&gt; &gt;&gt;&gt; t = test() &gt;&gt;&gt; t.__next__() 0 &gt;&gt;&gt; t.__next__() None 1 &gt;&gt;&gt; next(t) None 2 &gt;&gt;&gt; t.send(&apos;hehe&apos;) hehe 3","categories":[{"name":"python","slug":"python","permalink":"http://yoursite.com/categories/python/"}],"tags":[{"name":"迭代 列表生成式 生成器 yieid","slug":"迭代-列表生成式-生成器-yieid","permalink":"http://yoursite.com/tags/迭代-列表生成式-生成器-yieid/"}]},{"title":"python之闭包","slug":"闭包","date":"2017-03-12T16:00:00.000Z","updated":"2018-03-06T13:43:17.384Z","comments":true,"path":"2017/03/13/闭包/","link":"","permalink":"http://yoursite.com/2017/03/13/闭包/","excerpt":"","text":"如果在一个函数的内部定义了另一个函数，外部的我们叫他外函数，内部的我们叫他内函数。 闭包三要素： 1，在一个外函数中定义了一个内函数， 2，内函数里运用了外函数的临时变量， 3，并且外函数的返回值是内函数的引用。 这样就构成了一个闭包。 一般情况下，在我们认知当中，如果一个函数结束，函数的内部所有东西都会释放掉，还给内存，局部变量都会消失。但是闭包是一种特殊情况，如果外函数在结束的时候发现有自己的临时变量将来会在内部函数中用到，就把这个临时变量绑定给了内部函数，然后自己再结束。 #闭包函数的实例 # outer是外部函数 a和b都是外函数的临时变量 def outer( a ): b = 10 # inner是内函数 def inner(): #在内函数中 用到了外函数的临时变量 print(a+b) # 外函数的返回值是内函数的引用 return inner if __name__ == &apos;__main__&apos;: # 在这里我们调用外函数传入参数5 #此时外函数两个临时变量 a是5 b是10 ，并创建了内函数，然后把内函数的引用返回存给了demo # 外函数结束的时候发现内部函数将会用到自己的临时变量，这两个临时变量就不会释放，会绑定给这个内部函数 demo = outer(5) # 我们调用内部函数，看一看内部函数是不是能使用外部函数的临时变量 # demo存了外函数的返回值，也就是inner函数的引用，这里相当于执行inner函数 demo() # 15 demo2 = outer(7) demo2()#17 1 外函数返回了内函数的引用： 引用是什么？在python中一切都是对象，包括整型数据1，函数，其实是对象。 当我们进行a=1的时候，实际上在内存当中有一个地方存了值1，然后用a这个变量名存了1所在内存位置的引用。大家可以把引用理解成地址。a只不过是一个变量名字，a里面存的是1这个数值所在的地址，就是a里面存了数值1的引用。 相同的道理，当我们在python中定义一个函数def demo(): 的时候，内存当中会开辟一些空间，存下这个函数的代码、内部的局部变量等等。这个demo只不过是一个变量名字，它里面存了这个函数所在位置的引用而已。我们还可以进行x = demo， y = demo， 这样的操作就相当于，把demo里存的东西赋值给x和y，这样x 和y 都指向了demo函数所在的引用，在这之后我们可以用x() 或者 y() 来调用我们自己创建的demo() ，调用的实际上根本就是一个函数，x、y和demo三个变量名存了同一个函数的引用。 不知道大家有没有理解，很晦涩，希望我说明白了我想表达的。 有了上面的解释，我们可以继续说，返回内函数的引用是怎么回事了。对于闭包，在外函数outer中 最后return inner，我们在调用外函数 demo = outer() 的时候，outer返回了inner，inner是一个函数的引用，这个引用被存入了demo中。所以接下来我们再进行demo() 的时候，相当于运行了inner函数。 同时我们发现，一个函数，如果函数名后紧跟一对括号，相当于现在我就要调用这个函数，如果不跟括号，相当于只是一个函数的名字，里面存了函数所在位置的引用。 2 外函数把临时变量绑定给内函数： 按照我们正常的认知，一个函数结束的时候，会把自己的临时变量都释放还给内存，之后变量都不存在了。一般情况下，确实是这样的。但是闭包是一个特别的情况。外部函数发现，自己的临时变量会在将来的内部函数中用到，自己在结束的时候，返回内函数的同时，会把外函数的临时变量送给内函数绑定在一起。所以外函数已经结束了，调用内函数的时候仍然能够使用外函数的临时变量。 在我编写的实例中，我两次调用外部函数outer,分别传入的值是5和7。内部函数只定义了一次，我们发现调用的时候，内部函数是能识别外函数的临时变量是不一样的。python中一切都是对象，虽然函数我们只定义了一次，但是外函数在运行的时候，实际上是按照里面代码执行的，外函数里创建了一个函数，我们每次调用外函数，它都创建一个内函数，虽然代码一样，但是却创建了不同的对象，并且把每次传入的临时变量数值绑定给内函数，再把内函数引用返回。虽然内函数代码是一样的，但其实，我们每次调用外函数，都返回不同的实例对象的引用，他们的功能是一样的，但是它们实际上不是同一个函数对象。 闭包中内函数修改外函数局部变量： 在闭包内函数中，我们可以随意使用外函数绑定来的临时变量，但是如果我们想修改外函数临时变量数值的时候发现出问题了！ 在基本的python语法当中，一个函数可以随意读取全局数据，但是要修改全局数据的时候有两种方法:1 global 声明全局变量 2 全局变量是可变类型数据的时候可以修改 在闭包内函数也是类似的情况。在内函数中想修改闭包变量（外函数绑定给内函数的局部变量）的时候： 1 在python3中，可以用nonlocal 关键字声明 一个变量， 表示这个变量不是局部变量空间的变量，需要向上一层变量空间找这个变量。 2 在python2中，没有nonlocal这个关键字，我们可以把闭包变量改成可变类型数据进行修改，比如列表。 #修改闭包变量的实例 # outer是外部函数 a和b都是外函数的临时变量 def outer( a ): b = 10 # a和b都是闭包变量 c = [a] #这里对应修改闭包变量的方法2 # inner是内函数 def inner(): #内函数中想修改闭包变量 # 方法1 nonlocal关键字声明 nonlocal b b+=1 # 方法二，把闭包变量修改成可变数据类型 比如列表 c[0] += 1 print(c[0]) print(b) # 外函数的返回值是内函数的引用 return inner if __name__ == &apos;__main__&apos;: demo = outer(5) demo() # 6 11 从上面代码中我们能看出来，在内函数中，分别对闭包变量进行了修改，打印出来的结果也确实是修改之后的结果。以上两种方法就是内函数修改闭包变量的方法。 还有一点需要注意：使用闭包的过程中，一旦外函数被调用一次返回了内函数的引用，虽然每次调用内函数，是开启一个函数执行过后消亡，但是闭包变量实际上只有一份，每次开启内函数都在使用同一份闭包变量 def outer(x): def inner(y): nonlocal x x+=y return x return inner a = outer(10) print(a(1)) //11 print(a(3)) //14 两次分别打印出11和14，由此可见，每次调用inner的时候，使用的闭包变量x实际上是同一个。","categories":[{"name":"python","slug":"python","permalink":"http://yoursite.com/categories/python/"}],"tags":[{"name":"闭包","slug":"闭包","permalink":"http://yoursite.com/tags/闭包/"}]},{"title":"python之常用模块块","slug":"常用模块","date":"2017-03-09T16:00:00.000Z","updated":"2018-03-01T13:42:28.550Z","comments":true,"path":"2017/03/10/常用模块/","link":"","permalink":"http://yoursite.com/2017/03/10/常用模块/","excerpt":"","text":"python有一套很有用的标准库，标准库会随着python解释器，一起安装在你的电脑中的。它是python的一个组成部分，这些标准库是Python为你准备好的利器，可以让编程事半功倍。 标准库 说明 builtins 内建函数默认加载 os 操作系统接口 sys Python自身的运行环境 functools 常用的工具 json 编码和解码JSON对象 logging 记录日志，调试 multiprocessing 多进程 threading 多线程 copy 拷贝 time 时间 datetime 日期和时间 calendar 日历 hashlib 加密算法 random 生成随机数 re 字符串正则匹配 socket 标准的BSD Sockets API shutil 文件和目录管理 glob 基于文件通配符搜索 1，hashlib 加密算法，主要用于注册登录加密 &gt;&gt;&gt; import hashlib &gt;&gt;&gt; t = hashlib.md5() #创建hash对象，md5 &gt;&gt;&gt; t.update(b&apos;yanruilong&apos;) #更新哈希对象传一个字符串参数 &gt;&gt;&gt; t.hexdigest() #返回十六进制数字字符串 &apos;3e0474ae09c74b6276d23eb56b1209da&apos;","categories":[{"name":"python","slug":"python","permalink":"http://yoursite.com/categories/python/"}],"tags":[{"name":"常用模块","slug":"常用模块","permalink":"http://yoursite.com/tags/常用模块/"}]}]}